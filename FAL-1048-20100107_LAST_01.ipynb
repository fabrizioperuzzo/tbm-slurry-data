{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env conda run -n datimacchinaenv python\n",
    "import sys\n",
    "print(sys.executable)    ### C:\\ProgramData\\Anaconda3_1\\envs\\datimacchinaenv\\python.exe\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !{sys.executable} -m pip install xlwt\n",
    "# !{sys.executable} -m pip install openpyxl\n",
    "# !{sys.executable} -m pip install Pillow\n",
    "# !{sys.executable} -m pip install seaborn\n",
    "# !conda install --yes --prefix {sys.prefix} xlrd \n",
    "# !{sys.executable} -m pip install tables     \n",
    "# !{sys.executable} -m pip install simpledbf\n",
    "import sys\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None  ## in order to show all columns\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as IPdisplay\n",
    "import shutil\n",
    "# per matrice correlazione\n",
    "import seaborn as sns\n",
    "# Scipy helper functions\n",
    "from scipy.stats import percentileofscore\n",
    "from scipy import stats\n",
    "import matplotlib.tri as mtri\n",
    "import datetime as dt\n",
    "import h5py\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib.pyplot import figure\n",
    "import xlwt  # necessario per esportare xls con pandas\n",
    "from scipy.interpolate import griddata\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from images2gif import writeGif  # requires --> (datimacchinaenv) pip install images2gif\n",
    "\n",
    "#####   important before to start do the same change to the package images2gif   ###########\n",
    "\n",
    "#       manually change the two import statements in your already installed package (in __init__.py):\n",
    "\n",
    "#       -from images2gif import readGif as readGif\n",
    "#       -from images2gif import writeGif as writeGif\n",
    "#       +from .images2gif import readGif as readGif\n",
    "#       +from .images2gif import writeGif as writeGif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+'\\\\DATA\\\\20200107'\n",
    "\n",
    "files = []\n",
    "filespath = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if r'MERGE' in file:\n",
    "            files.append(file)\n",
    "            filespath.append(os.path.join(r, file))\n",
    "            \n",
    "# since there is only one file I need only the file name\n",
    "os.path.join(r, files[0])\n",
    "\n",
    "print(files)\n",
    "print(filespath)\n",
    "df = pd.read_excel(os.path.join(r, files[0]))\n",
    "print('file loaded'+files[0])\n",
    "print('\\nColumns list:')\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD MULTI FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.getcwd()+'\\\\DATA\\\\1048'\n",
    "path = os.getcwd()+'\\\\DATA2'\n",
    "\n",
    "files = []\n",
    "filespath = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.xls' in file:\n",
    "            files.append(file)\n",
    "            filespath.append(os.path.join(r, file))\n",
    "            \n",
    "# since there is only one file I need only the file name\n",
    "os.path.join(r, files[0])\n",
    "#check the first and last 5 files if correctly in list \"files\"\n",
    "print('primi 5 files',files[:5])\n",
    "print('ultimi 6 files',files[-6:])\n",
    "print('primi 2 filespath',filespath[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls=pd.DataFrame({})\n",
    "n=0\n",
    "for file in filespath:\n",
    "    try:\n",
    "        xlstemp = pd.read_excel(file, 'Sheet0')\n",
    "        #xlstemp['CPTname']=file.replace('.xls','')\n",
    "        dfxls = dfxls.append(xlstemp, ignore_index = True, sort=True)\n",
    "        n+=1\n",
    "        if n%10==0: print(n)\n",
    "    except:\n",
    "        print('A file was not loaded')\n",
    "%reset_selective -f \"^xlstemp$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SAVE AND LOAD AS H5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.to_hdf('1048_2020.h5', key='losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls = pd.read_hdf('1048_2020.h5', key='losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfxls.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAN DATA AND CREATE NEW COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Drop double columns ending by .1\n",
    "\n",
    "df.filter(regex='[.]1$')\n",
    "df = df[df.columns.drop(list(df.filter(regex='[.]1$')))]  # per eliminare eventuali colonne doppie\n",
    "\n",
    "###  Create new columns\n",
    "\n",
    "#### First we create a column that can be detected as date\n",
    "\n",
    "df['datestamp']=pd.to_datetime(df.Date)\n",
    "df['timestamp']=df.datestamp.apply(lambda x: int(time.mktime(x.timetuple())))\n",
    "\n",
    "df.sort_values('timestamp',inplace=True)\n",
    "\n",
    "#### Then we find the position of relevant indicators  --> do not remove spaces before this \n",
    "\n",
    "# cerco la posizione delle colonne principali\n",
    " \n",
    "# regex  --> (?i) means case unsensible\n",
    "\n",
    "pos_filllev=int(df.columns.get_loc(df.filter(regex='(?i)fill.*lev.*work.*chamb').columns.tolist()[0]))\n",
    "pos_stroke=int(df.columns.get_loc(df.filter(regex='(?i)aet.*stroke').columns.tolist()[0]))\n",
    "pos_p01=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)P0.1)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_p02=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)P0.2)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_p03=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)P0.3)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_p04=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)P0.4)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_p05=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)P0.5)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "# non presenti nella lista erano usate per correggere il feed \n",
    "# pos_pos02=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)posit)(?=.*(?i)2)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "# pos_pos03=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)posit)(?=.*(?i)3)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_advspeed=int(df.columns.get_loc(df.filter(regex='(?i)Advance.*speed.*').columns.tolist()[0]))\n",
    "pos_torque=int(df.columns.get_loc(df.filter(regex='(?i)torque.*cutting.*wheel.*').columns.tolist()[0]))\n",
    "pos_feed=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)flow)(?=.*(?i)feed)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_slurry=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)slurry)(?=.*(?i)line)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_num=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)1048)(?=.*(?i)advance)(?=.*(?i)[-]).*$').columns.tolist()[0]))\n",
    "pos_prch01=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)1)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch02=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)2)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch03=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)3)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch04=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)4)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch05=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)5)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch06=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)6)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch07=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)7)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch08=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)8)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_date=int(df.columns.get_loc(df.filter(regex='datestamp').columns.tolist()[0]))\n",
    "pos_timestamp=int(df.columns.get_loc(df.filter(regex='timestamp').columns.tolist()[0]))\n",
    "# densities\n",
    "pos_dens_p04=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)dens)(?=.*(?i)p04)(?=.*(?i)t/m).*$').columns.tolist()[0]))\n",
    "pos_dens_slurry=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)dens)(?=.*(?i)slurr)(?=.*(?i)line)(?=.*(?i)t/m³).*$').columns.tolist()[0]))\n",
    "pos_dens_feed=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)dens)(?=.*(?i)feed)(?=.*(?i)line)(?=.*(?i)t/m³).*$').columns.tolist()[0]))\n",
    "# stroke cyl abcde\n",
    "pos_cy_a=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)strok)(?=.*(?i)cyl)(?=.*(?i) A ).*$').columns.tolist()[0]))\n",
    "pos_cy_b=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)strok)(?=.*(?i)cyl)(?=.*(?i) B ).*$').columns.tolist()[0]))\n",
    "pos_cy_c=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)strok)(?=.*(?i)cyl)(?=.*(?i) C ).*$').columns.tolist()[0]))\n",
    "pos_cy_d=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)strok)(?=.*(?i)cyl)(?=.*(?i) D ).*$').columns.tolist()[0]))\n",
    "pos_cy_e=int(df.columns.get_loc(df.filter(regex='^(?=.*(?i)strok)(?=.*(?i)cyl)(?=.*(?i) E ).*$').columns.tolist()[0]))\n",
    "\n",
    "col_list=df.columns.tolist()\n",
    "cl = col_list.copy()  # per chiamare la lista in maniera veloce\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creo colonne\n",
    "\n",
    "- **'datestamp_diff'** delta t tra righe in ore  **dt_h** nomesemplificato\n",
    "- **'stroke_diff[mm]'**  delta stroke corretto AET\n",
    "- **'stroke_diff_a[mm]'**  delta stroke a,b,c,d,e per ogni pistone\n",
    "\n",
    "- **'state1'** 1 se tutti i pistoni avanzano\n",
    "- **'state2'** 1 se AET net stroke avanza\n",
    "\n",
    "- **'state'** output 'fulloper','stall_rotating','stall_stand'\n",
    "\n",
    "- **'dfxls['vol_teor_cum[m³]']'**\n",
    "- **'dfxls['vol_teor_cum_dry[m³]']'**\n",
    "- **'dfxls['dvol_teor[m³]']'**\n",
    "\n",
    "- **'dfxls['dvol_calc[m³]']'**\n",
    "- **'dfxls['dvol_calc_MthE[m³]']'**\n",
    "\n",
    "- **'dfxls['dvol_teor-calc[m³]']'**   dvol_terico - dvol_calc\n",
    "\n",
    "\n",
    "- **col_list**  is a list for fast detection of columns\n",
    "- **pos_dict**  is a dictionary for fast detection of new created columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitialize the dataframe\n",
    "dfxls = df[(df.Date>\"2020-01-03\")&(df.Date<\"2020-01-04\")].copy()#     <-- Attenzione \n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Dati di input\n",
    "nw = 0.25 # indice dei vuoti\n",
    "rhosoil_ = 2.10 # t/m3 terreno in sito\n",
    "rhow = 1\n",
    "rhobent = 2.2\n",
    "Area_Cutter = 39.59\n",
    "\n",
    "## We create new columns\n",
    "\n",
    "#### Datestamp diff (aa-mm-gg hh-mm-ss)\n",
    "#### Datestamp diff [h]\n",
    "\n",
    "dfxls['datestamp_p'] = dfxls.datestamp.shift(1).copy()\n",
    "# Beign the first row == 0 we need to delete it _ but we will do it at the end otherwise we lose data\n",
    "#dfxls=dfxls.dropna().copy()\n",
    "\n",
    "dfxls['datestamp_diff']= dfxls['datestamp']-dfxls['datestamp_p']\n",
    "# dfxls['datestamp_diff2'] = dfxls['datestamp'].diff(periods=1).copy()  # stesso risultato come sopra\n",
    "\n",
    "dfxls['datestamp_diff[h]'] = dfxls['datestamp_diff'].astype('timedelta64[s]').fillna(0).copy()/3600\n",
    "dfxls['dt_h'] = dfxls['datestamp_diff[h]'].copy()\n",
    "\n",
    "#### Differenziali dpressure chambers loop sulle 8 celle di pressione\n",
    "\n",
    "for i in np.arange(1,9,1):\n",
    "    dfxls['dpress_ch{}'.format(i)] = dfxls[col_list[pos_prch01+i-1]].diff(periods=1).copy()\n",
    "\n",
    "#### Creo colonna stroke - delta stroke solo positivi - volumi teorici e volumi teorici cumulati        ['dVol_Teor[m³]']\n",
    "\n",
    "dfxls['stroke_diff[mm]'] = dfxls[col_list[pos_stroke]].diff(periods=1).fillna(0).copy()\n",
    "dfxls['stroke_diff_a[mm]'] = dfxls[col_list[pos_cy_a]].diff(periods=1).fillna(0).copy()\n",
    "dfxls['stroke_diff_b[mm]'] = dfxls[col_list[pos_cy_a]].diff(periods=1).fillna(0).copy()\n",
    "dfxls['stroke_diff_c[mm]'] = dfxls[col_list[pos_cy_a]].diff(periods=1).fillna(0).copy()\n",
    "dfxls['stroke_diff_d[mm]'] = dfxls[col_list[pos_cy_a]].diff(periods=1).fillna(0).copy()\n",
    "dfxls['stroke_diff_e[mm]'] = dfxls[col_list[pos_cy_a]].diff(periods=1).fillna(0).copy()\n",
    "\n",
    "\n",
    "# creazione indici di movimento\n",
    "def ff(row):\n",
    "    \n",
    "    if row['stroke_diff[mm]']>0 and row['stroke_diff_a[mm]']>0 and row['stroke_diff_b[mm]']>0 and\\\n",
    "       row['stroke_diff_c[mm]']>0 and row['stroke_diff_d[mm]']>0\\\n",
    "       and row['stroke_diff_e[mm]']>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "dfxls['state1'] = dfxls.apply(ff, axis=1)     # 0 se stop 1 se tutti i jack sono in movimento\n",
    "dfxls['dstroke[mm]'] = dfxls['AET Net Stroke [mm]'].diff(periods=1).fillna(0)  ## identico a dfxls['stroke_diff[mm]']\n",
    "dfxls['state2'] = dfxls['dstroke[mm]'].map(lambda x: 1 if x>0 else 0) # 1 se dstroke avanza 0 se fermo o negativo\n",
    "\n",
    "\n",
    "\n",
    "#####  Volumi dallo stroke\n",
    "    \n",
    "dfxls['dstroke_pos[mm]'] =dfxls[col_list[pos_stroke]].diff(periods=1).fillna(0).map(lambda x: 0 if x<0 else x).copy()   #è il dstroke solo positivo\n",
    "\n",
    "\n",
    "dfxls['nw'] = nw\n",
    "\n",
    "dfxls['vol_teor_cum[m³]'] = dfxls.iloc[:,pos_stroke]/1000*Area_Cutter    # use only to calculate dvol\n",
    "dfxls['vol_teor_cum_dry[m³]'] = dfxls['vol_teor_cum[m³]']*(1-dfxls.nw)         # use only to calculate dvol\n",
    "\n",
    "dfxls['dvol_teor[m³]'] = dfxls['vol_teor_cum[m³]'].diff(periods=1).fillna(0).map(lambda x: 0 if x<0 else x).copy()\n",
    "dfxls['dvol_teor_dry[m³]'] = dfxls['vol_teor_cum_dry[m³]'].diff(periods=1).fillna(0).map(lambda x: 0 if x<0 else x).copy()\n",
    "\n",
    "#### Calcolo di volumi dal Slurry-Feed * dt           ['dVol_bal_feed_slurry[m³]']\n",
    "\n",
    "# dfxls['feed_adj[m³/h]'] = dfxls[col_list[pos_feed]]-dfxls[col_list[pos_pos02]]-dfxls[col_list[pos_pos03]]  # incasina non togliere i sensori 2 e 3\n",
    "# dfxls['bal_feed_slurry[m³/h]']=dfxls[col_list[pos_slurry]]-dfxls['feed_adj[m³/h]']\n",
    "\n",
    "dfxls['bal_feed_slurry[m³/h]']=dfxls[col_list[pos_slurry]]-dfxls[col_list[pos_feed]]\n",
    "\n",
    "dfxls['dvol_bal_feed_slurry[m³]']=dfxls['bal_feed_slurry[m³/h]']*dfxls['datestamp_diff[h]']\n",
    "# dfxls['dvol_bal_feed_slurry_cum[m³]']=dfxls['dvol_bal_feed_slurry[m³]'].cumsum().shift(-1).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "#### Calcolo di volumi dal Slurry-Feed * dt   METHOD E\n",
    "\n",
    "dfxls['rhosoil'] = rhosoil_\n",
    "dfxls['rho_insitu'] = (dfxls.rhosoil *(1-dfxls.nw))+(dfxls.nw*rhow)\n",
    "\n",
    "dfxls['dvol_calc_MthE[m³]']=(\n",
    "                            (dfxls[col_list[pos_slurry]]*\n",
    "                            (dfxls[col_list[pos_dens_slurry]]-1)/(dfxls.rhosoil-1))-\n",
    "                            (dfxls[col_list[pos_feed]]*\n",
    "                            (dfxls[col_list[pos_dens_feed]]-1)/(dfxls.rhosoil-1))\n",
    "                            )*dfxls['datestamp_diff[h]']\n",
    "\n",
    "\n",
    "\n",
    "# dfxls['dvol_calc_MthE_cum[m³]']=dfxls['dvol_calc_MthE[m³]'].cumsum().shift(-1).fillna(0)\n",
    "\n",
    "\n",
    "#### Calcolo volumi dal fill level con formula polinomiale     ['dvol_work_chamb[m³]']\n",
    "\n",
    "def calcvolume(x):\n",
    "    vol=-0.113*x**5+0.1236*x**4+0.5462*x**3-0.1059*x**2+5.6112*x+11.794\n",
    "    if x > 0 : \n",
    "        return vol\n",
    "    elif x < 0 : \n",
    "        return vol\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "dfxls['instant_volume[m³]'] = dfxls[col_list[pos_filllev]].map(lambda x: calcvolume(x))\n",
    "dfxls['dvol_work_chamb[m³]'] = dfxls['instant_volume[m³]'].diff(periods=1).fillna(0).copy()\n",
    "# dfxls['dvol_work_chamb_cum[m³]'] = dfxls['dvol_work_chamb[m³]'].cumsum().shift(-1).fillna(0)\n",
    "\n",
    "#### Calcolo i balance istantanei e totali\n",
    "\n",
    "dfxls['dvol_calc[m³]'] = dfxls['dvol_work_chamb[m³]']+dfxls['dvol_bal_feed_slurry[m³]']\n",
    "\n",
    "dfxls['dvol_teor-calc[m³]'] = dfxls['dvol_teor[m³]']-dfxls['dvol_calc[m³]']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Creo la colonna STATE (fulloper,stall_rotating,stall_stand)\n",
    "\n",
    "dfxls['state']=0\n",
    "f_min_torq25 = dfxls.iloc[:,pos_torque].describe()[4]\n",
    "f_min_adv25 = dfxls.iloc[:,pos_advspeed].describe()[4]\n",
    "\n",
    "dfxls.loc[(dfxls[col_list[pos_torque]]>0) & (dfxls[col_list[pos_advspeed]]>0),'state'] = 'fulloper'\n",
    "dfxls.loc[(dfxls[col_list[pos_torque]]!=0) & (dfxls[col_list[pos_advspeed]]==0),'state'] = 'stall_rotating'\n",
    "dfxls.loc[(dfxls[col_list[pos_torque]]==0) & (dfxls[col_list[pos_advspeed]]==0),'state'] = 'stall_stand'\n",
    "\n",
    "### CREATE col_list for fast individuation of columns\n",
    "\n",
    "col_list=dfxls.columns.tolist()\n",
    "\n",
    "\n",
    "### creo pos_dict per le colonne nuove\n",
    "\n",
    "ls0 = []\n",
    "ls1 = []\n",
    "\n",
    "for i in col_list[111:]:\n",
    "    \n",
    "    ls0.append('pos_{}'.format(i.replace(\" \",'').split(\"[\")[0]))\n",
    "    ls1.append(dfxls.columns.get_loc(i))\n",
    "    \n",
    "pos_dict = dict(zip(ls0,ls1))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifiche aggiuntive\n",
    "- Correggo cambio concio colonna 'num_corr'\n",
    "- Creo colonna **'change'** False-True quando passo da:\n",
    "    - fermo( **'dstroke[mm]'** <=0 , **'state2'** =0)\n",
    "    - in movimento( **'dstroke[mm]'** >0 , **'state2'** =1)\n",
    "- Creo colonna **change** ovvero quando la macchina si ferma fz state2\n",
    "- Crea colonna **change2** ovvero quando la macchina riparte fz state2\n",
    "- Creo colonna **state3** basata su inizio fine processo\n",
    "- Creo colonna **num_corr** che è il numero di concio corretto\n",
    "- Creo colonna **'dstroke_pos[mm]'** e **'dstroke_pos_cum_seg[mm]'**\n",
    "  per tenere conto del solo stroke di avanzamento per concio\n",
    "- Calcolo i volumi cumulati:\n",
    "    - **'dvol_teor_cum_seg[m³]'**\n",
    "    - **'dvol_bal_feed_slurry_cum_seg[m³]'**\n",
    "    - **'dvol_work_chamb_cum_seg[m³]'**\n",
    "    - **'dvol_calc_cum_seg[m³]'**\n",
    "    - **'dvol_teor-calc_cum_seg[m³]'**\n",
    "    - **'dvol_calc_MthE_cum_seg[m³]'**\n",
    "    - **theormass1** **theormass2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# creo colonna 'num_corr' \n",
    "\n",
    "dfxls.reset_index(drop=True)\n",
    "for index, row in dfxls.iterrows():\n",
    "    if index==0: numconcio = dfxls.iloc[0,pos_num]\n",
    "    dfxls.loc[index,'num_corr'] = numconcio\n",
    "    if index > 1 and row['dstroke[mm]']==0 and rowp['dstroke[mm]']>0 and row[col_list[pos_stroke]]>1500:\n",
    "        numconcio += 1\n",
    "        dfxls.loc[index,'num_corr'] = numconcio\n",
    "    rowp = row\n",
    "\n",
    "\n",
    "# creo colonna change in base a 'state2'\n",
    "\n",
    "dfxls['change'] = dfxls['state2'].gt(dfxls['state2'].shift())\n",
    "dfxls['change2'] = dfxls['state2'].shift().gt(dfxls['state2'])\n",
    "\n",
    "dic_start = dfxls[dfxls['change']==True].groupby(col_list[pos_num]).agg({col_list[pos_timestamp]:min}).to_dict()\n",
    "dic_start = dic_start[list(dic_start.keys())[0]]\n",
    "\n",
    "dic_end = dfxls[dfxls['change2']==True].groupby(col_list[pos_num]).agg({col_list[pos_timestamp]:max}).to_dict()\n",
    "dic_end = dic_end[list(dic_end.keys())[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# creo colonna change in base a 'state3'   Inizio fine processo di avanzamento senza tener conto di stop intermedi\n",
    "\n",
    "def ffstate3(row):\n",
    "    try:\n",
    "        if row[col_list[pos_timestamp]]<dic_start[row['num_corr']]:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "    try:\n",
    "        if row[col_list[pos_timestamp]]>=dic_start[row['num_corr']]:\n",
    "            return 1\n",
    "    except:\n",
    "        return 0\n",
    "    try:\n",
    "        if row[col_list[pos_timestamp]]>dic_end[row['num_corr']]:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "dfxls['state3'] = 0\n",
    "dfxls['state3'] = dfxls.apply(ffstate3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "######     RAGGRUPPO     PER  SEGMENT                                   ******* GROUP ********\n",
    "\n",
    "\n",
    "    \n",
    "gr = dfxls[dfxls.state3==1].groupby('num_corr')\n",
    "# gr = dfxls.groupby('num_corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "dfxls['dstroke_pos_cum_seg[mm]'] = gr['dstroke_pos[mm]'].cumsum().fillna(0)\n",
    "dfxls['dstroke_cum_seg[mm]'] = gr['dstroke[mm]'].cumsum().fillna(0)               # <---- è quello corretto perchè tiene conto di un possibile x0!=0\n",
    "dfxls['dstroke_pos_cum_seg[mm]'].fillna(0)\n",
    "dfxls['dstroke_cum_seg[mm]'].fillna(0, inplace=True)\n",
    "\n",
    "## CALCOLO I VOLUMI CUMULATI    \n",
    "\n",
    "dfxls['dvol_teor_cum_seg[m³]'] = gr['dvol_teor[m³]'].cumsum().fillna(0)                            # non fare shift\n",
    "dfxls['dvol_teor_dry_cum_seg[m³]'] = gr['dvol_teor_dry[m³]'].cumsum().fillna(0)\n",
    "\n",
    "dfxls['dvol_bal_feed_slurry_cum_seg[m³]'] = gr['dvol_bal_feed_slurry[m³]'].cumsum().fillna(0)     # non fare .shift(-1).fillna(0)\n",
    "dfxls['dvol_work_chamb_cum_seg[m³]'] = gr['dvol_work_chamb[m³]'].cumsum().fillna(0)\n",
    "dfxls['dvol_calc_cum_seg[m³]'] = gr['dvol_calc[m³]'].cumsum().fillna(0)\n",
    "dfxls['dvol_teor-calc_cum_seg[m³]'] = gr['dvol_teor-calc[m³]'].cumsum().fillna(0)\n",
    "dfxls['dvol_calc_MthE_cum_seg[m³]'] = gr['dvol_calc_MthE[m³]'].cumsum().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### DRY MASS CONTROL PARAMETERS\n",
    "\n",
    " 1. Teoretical Mass (Stroke*Area*Density insitu)  **'theormass1'**\n",
    " 2. Calc dry mass A(particle+bentonite)           **'metha'**\n",
    " 3. Calc dry mass B(gener solid + fixed water)    **'methb'**\n",
    " 4. Calc dry mass C(insitu density)               **'methc'**\n",
    " 5. Calc dry mass D(particle + insitu density)    **'methd'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Theoretical mass\n",
    "\n",
    "\n",
    "dfxls['dtheormass2'] = Area_Cutter * dfxls.rho_insitu *(dfxls[cl[pos_advspeed]]*60/1000*dfxls['datestamp_diff[h]'])[dfxls.state3==1] \n",
    "dfxls['dtheormass2'].fillna(0)\n",
    "\n",
    "dfxls['metha1'] = dfxls[cl[pos_feed]]*rhobent*(dfxls[cl[pos_dens_feed]]-rhow)/(rhobent-rhow)\n",
    "dfxls['metha2'] = dfxls[cl[pos_slurry]]*dfxls.rhosoil*(dfxls[cl[pos_dens_slurry]]-rhow)/(dfxls.rhosoil-rhow)\n",
    "dfxls['metha3'] = (dfxls.metha2 - dfxls.metha1)*dfxls.dt_h[dfxls.state3==1] \n",
    "\n",
    "\n",
    "dfxls['methb1'] = ((dfxls[cl[pos_slurry]]*(dfxls[cl[pos_dens_slurry]]-rhow))-(dfxls[cl[pos_feed]]*(dfxls[cl[pos_dens_feed]]-rhow)))*dfxls.rhosoil / (dfxls.rhosoil-rhow)*dfxls.dt_h\n",
    "\n",
    "\n",
    "dfxls['methc1'] = ((dfxls[cl[pos_slurry]]*dfxls[cl[pos_dens_slurry]])-(dfxls[cl[pos_feed]]*dfxls[cl[pos_dens_feed]]))/(dfxls.rho_insitu - dfxls[cl[pos_dens_feed]])*dfxls.dt_h\n",
    "\n",
    "\n",
    "dfxls['methd1'] = ((dfxls[cl[pos_slurry]]*(dfxls[cl[pos_dens_slurry]]-rhow))-(dfxls[cl[pos_feed]]*(dfxls[cl[pos_dens_feed]]-rhow)))/(dfxls.rho_insitu - dfxls[cl[pos_dens_feed]])*dfxls.dt_h\n",
    "dfxls['methd2'] = (dfxls.methd1 * dfxls.rhosoil/(dfxls.rhosoil-rhow))+dfxls['dvol_work_chamb[m³]']*dfxls[cl[pos_dens_slurry]]\n",
    "\n",
    "\n",
    "\n",
    "######     RAGGRUPPO     PER  SEGMENT                                   ******* GROUP ********\n",
    "\n",
    "    \n",
    "gr = dfxls[dfxls.state3==1].groupby('num_corr')\n",
    "# gr = dfxls.groupby('num_corr')\n",
    "\n",
    "\n",
    "dfxls['theormass1'] = Area_Cutter * dfxls.rho_insitu * dfxls['dstroke_pos_cum_seg[mm]']/1000\n",
    "dfxls['theormass2'] = gr['dtheormass2'].cumsum().fillna(0)\n",
    "dfxls['metha'] = gr.metha3.cumsum().fillna(0)\n",
    "dfxls['methb'] = gr.methb1.cumsum().fillna(0)\n",
    "dfxls['methc'] = gr.methc1.cumsum().fillna(0)\n",
    "dfxls['methd'] = gr.methd2.cumsum().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FACE PRESSURE CONTROL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Posizione dei sensori\n",
    "\n",
    "z_s8 = 2.9\n",
    "z_s17 = 1.8\n",
    "z_s2 = 0.3\n",
    "z_s36 = -0.6\n",
    "z_s45 = -1.9\n",
    "\n",
    "z_s1 = z_s17\n",
    "z_s7 = z_s17\n",
    "z_s3 = z_s36\n",
    "z_s6 = z_s36\n",
    "z_s4 = z_s45\n",
    "z_s5 = z_s45\n",
    "\n",
    "x_s1 = 1.664\n",
    "x_s2 = 2.031\n",
    "x_s3 = 3.033\n",
    "x_s4 = 1.628\n",
    "x_s5 = -1.608\n",
    "x_s6 = -2.95\n",
    "x_s7 = -1.737\n",
    "x_s8 = -0.867\n",
    "\n",
    "\n",
    "dfxls['rhopat'] = 1.25\n",
    "\n",
    "\n",
    "dfxls['paau_s8'] = 2.36\n",
    "dfxls['pau_s8'] = 1.98\n",
    "dfxls['pn_s8']   = 1.8\n",
    "dfxls['pal_s8'] = 1.71 \n",
    "dfxls['paal_s8'] = 1.62\n",
    "\n",
    "lista_sens = ['s17','s2','s36','s45']\n",
    "\n",
    "for i in lista_sens:\n",
    "       \n",
    "    dfxls[('paau_{}').format(i)] = dfxls['paau_s8'] + dfxls[cl[pos_dens_p04]] * (z_s8-vars()[('z_{}').format(i)])/10\n",
    "    dfxls[('pau_{}').format(i)] = dfxls['pau_s8'] + dfxls[cl[pos_dens_p04]] * (z_s8-vars()[('z_{}').format(i)])/10\n",
    "    dfxls[('pn_{}').format(i)] = dfxls['pn_s8'] + dfxls[cl[pos_dens_p04]] * (z_s8-vars()[('z_{}').format(i)])/10\n",
    "    dfxls[('pal_{}').format(i)] = dfxls['pal_s8'] + dfxls[cl[pos_dens_p04]] * (z_s8-vars()[('z_{}').format(i)])/10\n",
    "    dfxls[('paal_{}').format(i)] = dfxls['paal_s8'] + dfxls[cl[pos_dens_p04]] * (z_s8-vars()[('z_{}').format(i)])/10\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "dfxls[['paal_s36','paau_s36','pal_s36','pau_s36','pn_s36','pn_s8']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RISK LEVEL PER SENSOR CHAMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_sens = ['s1','s2','s3','s4','s5','s6','s7','s8']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### risk \n",
    "# 4: upper alarm level passed\n",
    "# 3: upper alert level passed\n",
    "# 2: normal\n",
    "# 1: lower alert level passed\n",
    "# 0: lower alarm level passed\n",
    "        \n",
    "    \n",
    "    \n",
    "dfxls['risk_s1'] = dfxls.apply(lambda x: 4 if x[cl[pos_prch01]]>x['paau_s17'] else (\n",
    "                               3 if x[cl[pos_prch01]]>x['pau_s17'] else (\n",
    "                               0 if x[cl[pos_prch01]]<x['paal_s17'] else (\n",
    "                               1 if x[cl[pos_prch01]]<x['pal_s17'] else 2))),\n",
    "                               axis=1)  \n",
    "\n",
    "dfxls['risk_s2'] = dfxls.apply(lambda x: 4 if x[cl[pos_prch02]]>x['paau_s2'] else (\n",
    "                               3 if x[cl[pos_prch02]]>x['pau_s2'] else (\n",
    "                               0 if x[cl[pos_prch02]]<x['paal_s2'] else (\n",
    "                               1 if x[cl[pos_prch02]]<x['pal_s2'] else 2))),\n",
    "                               axis=1) \n",
    "\n",
    "dfxls['risk_s3'] = dfxls.apply(lambda x: 4 if x[cl[pos_prch03]]>x['paau_s36'] else (\n",
    "                               3 if x[cl[pos_prch03]]>x['pau_s36'] else (\n",
    "                               0 if x[cl[pos_prch03]]<x['paal_s36'] else (\n",
    "                               1 if x[cl[pos_prch03]]<x['pal_s36'] else 2))),\n",
    "                               axis=1) \n",
    "\n",
    "dfxls['risk_s4'] = dfxls.apply(lambda x: 4 if x[cl[pos_prch04]]>x['paau_s45'] else (\n",
    "                               3 if x[cl[pos_prch04]]>x['pau_s45'] else (\n",
    "                               0 if x[cl[pos_prch04]]<x['paal_s45'] else (\n",
    "                               1 if x[cl[pos_prch04]]<x['pal_s45'] else 2))),\n",
    "                               axis=1) \n",
    "\n",
    "dfxls['risk_s5'] = dfxls.apply(lambda x: 4 if x[cl[pos_prch05]]>x['paau_s45'] else (\n",
    "                               3 if x[cl[pos_prch05]]>x['pau_s45'] else (\n",
    "                               0 if x[cl[pos_prch05]]<x['paal_s45'] else (\n",
    "                               1 if x[cl[pos_prch05]]<x['pal_s45'] else 2))),\n",
    "                               axis=1) \n",
    "\n",
    "dfxls['risk_s6'] = dfxls.apply(lambda x: 4 if x[cl[pos_prch06]]>x['paau_s36'] else (\n",
    "                               3 if x[cl[pos_prch06]]>x['pau_s36'] else (\n",
    "                               0 if x[cl[pos_prch06]]<x['paal_s36'] else (\n",
    "                               1 if x[cl[pos_prch06]]<x['pal_s36'] else 2))),\n",
    "                               axis=1) \n",
    "\n",
    "dfxls['risk_s7'] = dfxls.apply(lambda x: 4 if x[cl[pos_prch07]]>x['paau_s17'] else (\n",
    "                               3 if x[cl[pos_prch07]]>x['pau_s17'] else (\n",
    "                               0 if x[cl[pos_prch07]]<x['paal_s17'] else (\n",
    "                               1 if x[cl[pos_prch07]]<x['pal_s17'] else 2))),\n",
    "                               axis=1) \n",
    "\n",
    "dfxls['risk_s8'] = dfxls.apply(lambda x: 4 if x[cl[pos_prch08]]>x['paau_s8'] else (\n",
    "                               3 if x[cl[pos_prch08]]>x['pau_s8'] else (\n",
    "                               0 if x[cl[pos_prch08]]<x['paal_s8'] else (\n",
    "                               1 if x[cl[pos_prch08]]<x['pal_s8'] else 2))),\n",
    "                               axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DENS CALC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.d87 = (dfxls[cl[pos_prch07]]-dfxls[cl[pos_prch08]])/abs(z_s7-z_s8)*10\n",
    "dfxls.d81 = (dfxls[cl[pos_prch01]]-dfxls[cl[pos_prch08]])/abs(z_s1-z_s8)*10\n",
    "\n",
    "dfxls.d82 = (dfxls[cl[pos_prch02]]-dfxls[cl[pos_prch08]])/abs(z_s2-z_s8)*10\n",
    "\n",
    "dfxls.d76 = (dfxls[cl[pos_prch06]]-dfxls[cl[pos_prch07]])/abs(z_s6-z_s7)*10\n",
    "dfxls.d13 = (dfxls[cl[pos_prch03]]-dfxls[cl[pos_prch01]])/abs(z_s3-z_s1)*10\n",
    "\n",
    "dfxls.d76 = (dfxls[cl[pos_prch05]]-dfxls[cl[pos_prch06]])/abs(z_s5-z_s6)*10\n",
    "dfxls.d73 = (dfxls[cl[pos_prch04]]-dfxls[cl[pos_prch03]])/abs(z_s4-z_s3)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lista delle variabili create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lista delle variabili create\n",
    "\n",
    "# 'vol_teor_cum[m³]'         # usare 'dvol_teor_cum_seg[m³]'\n",
    "# 'dvol_teor[m³]'\n",
    "# 'dvol_bal_feed_slurry[m³]'    \n",
    "# 'dvol_work_chamb[m³]'\n",
    "# 'dvol_calc[m³]'\n",
    "# 'dvol_calc_MthE[m³]'\n",
    "# 'dvol_teor-calc[m³]'\n",
    "# 'dvol_teor_cum_seg[m³]'\n",
    "# 'dvol_bal_feed_slurry_cum_seg[m³]'\n",
    "# 'dvol_work_chamb_cum_seg[m³]'\n",
    "# 'dvol_calc_cum_seg[m³]'\n",
    "# 'dvol_teor-calc_cum_seg[m³]'\n",
    "# 'dvol_calc_MthE_cum_seg[m³]'\n",
    "\n",
    "# 'theormass'\n",
    "# 'metha'\n",
    "# 'methb'\n",
    "# 'methc'\n",
    "# 'methd'\n",
    "\n",
    "# paal_s36\n",
    "# paau_s36\n",
    "# pal_s36\n",
    "# pau_s36\n",
    "# pn_s36\n",
    "\n",
    "# z_s1\n",
    "# x_s1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dfxls.d87\n",
    "# dfxls.d81\n",
    "# dfxls.d82\n",
    "# dfxls.d76\n",
    "# dfxls.d13\n",
    "# dfxls.d76\n",
    "# dfxls.d73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT Get Ready to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxlscopy = dfxls.copy()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment 1859-1931\n",
    "\n",
    "rigainizio = 0  # 0    per partire dalla prima  riga inziale\n",
    "rigafine = -1     #-1   riga finale \n",
    "dstep    = 1     #  1   detaspet uguale al db 30sec o 10sec\n",
    "\n",
    "df1 = dfxlscopy.iloc[rigainizio:rigafine,:].reset_index(drop=True)\n",
    "\n",
    "n_row = df1.shape[0]\n",
    "n_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo una lista con data, sensori delle camere, fill, \n",
    "list_chamb = []\n",
    "for i in dfxls.filter(regex='Pressure excavation chamber'):\n",
    "    list_chamb.append(dfxls.columns.get_loc(i))\n",
    "print('List of chamber columns is:',list_chamb)\n",
    "\n",
    "list_col = [0]\n",
    "list_col.extend(list_chamb)\n",
    "list_col.append(pos_filllev)\n",
    "list_col.extend([dfxls.columns.get_loc('risk_s1'),dfxls.columns.get_loc('risk_s2'),dfxls.columns.get_loc('risk_s3'),dfxls.columns.get_loc('risk_s4'),\n",
    "               dfxls.columns.get_loc('risk_s5'),dfxls.columns.get_loc('risk_s6'),dfxls.columns.get_loc('risk_s7'),dfxls.columns.get_loc('risk_s8')])\n",
    "print('List of interesting columns',list_col)\n",
    "\n",
    "# *************************************************\n",
    "\n",
    "n_sensori = 8\n",
    "\n",
    "list_x = [x_s1,x_s2,x_s3,x_s4,x_s5,x_s6,x_s7,x_s8]\n",
    "list_z = [z_s1,z_s2,z_s3,z_s4,z_s5,z_s6,z_s7,z_s8]\n",
    "\n",
    "# zeta sfalsate per plot \n",
    "list_z1 = [z_s1-0.5,z_s2,z_s3-0.5,z_s4,z_s5-0.5,z_s6,z_s7,z_s8]\n",
    "\n",
    "print(list_x)\n",
    "print(list_z)\n",
    "\n",
    "# list_x = []\n",
    "# list_z = []\n",
    "# for i in np.arange(0,n_sensori,1):\n",
    "#     x = 1 * np.sin(2*np.pi/8*i)\n",
    "#     list_x.append(x)\n",
    "#     z = 1 * np.cos(2*np.pi/8*i)\n",
    "#     list_z.append(z)\n",
    "\n",
    "\n",
    "    \n",
    "df2 = dfxlscopy.iloc[rigainizio:rigafine,list_col].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ************************************************\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "save_folder = 'images/gif'\n",
    "gif_filename = '01'\n",
    "\n",
    "shutil.rmtree(save_folder, ignore_errors=True)\n",
    "\n",
    "working_folder = '{}/{}'.format(save_folder, gif_filename)\n",
    "\n",
    "if not os.path.exists(working_folder):\n",
    "    os.makedirs(working_folder)\n",
    "    \n",
    "    \n",
    "fontdicttitlebig={'fontsize': 20,\n",
    "          'fontweight':0.1,\n",
    "          'horizontalalignment': 'center'}    \n",
    "\n",
    "fontdict1={'fontsize': 18,\n",
    "          'fontweight':0.1,\n",
    "          'horizontalalignment': 'center'}\n",
    "\n",
    "fontdict2 = {'family': 'arial',\n",
    "        'color':  'white',\n",
    "        'weight': 'normal',\n",
    "        'size': 16,\n",
    "        }\n",
    "\n",
    "font_tx_graph = {'family': 'arial',\n",
    "        'color':  'white',\n",
    "        'weight': 'normal',\n",
    "        'size': 14,\n",
    "        }\n",
    "\n",
    "colorstate = {'fulloper':'limegreen','stall_rotating':'orange','stall_stand':'red'}\n",
    "textstate = {'fulloper':'OPERATION','stall_rotating':'ONLY ROTATING','stall_stand':'STOP'}\n",
    "colorfilllev = {True:'r',False:'b'}\n",
    "colorbalfs = {True:'r',False:'b'}\n",
    "\n",
    "colorrisk = {0:'tomato',1:'yellow',2:'springgreen',3:'yellow',4:'tomato'}\n",
    "\n",
    "cmap_segment = cm.get_cmap('jet')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Inizializzo le variabili indicatore\n",
    "\n",
    "\n",
    "n_sensori = 8\n",
    "\n",
    "\n",
    "\n",
    "changepoint = 0\n",
    "\n",
    "nseg = 0\n",
    "nseg_p = 0\n",
    "\n",
    "\n",
    "p_ch8_max = 0\n",
    "p_ch7_max = 0\n",
    "p_ch6_max = 0\n",
    "p_ch5_max = 0\n",
    "p_ch4_max = 0\n",
    "p_ch3_max = 0\n",
    "p_ch2_max = 0\n",
    "p_ch1_max = 0\n",
    "\n",
    "stroke = 0\n",
    "\n",
    "vol_teor_cum = 0\n",
    "vol_teor_cum_p = 0\n",
    "\n",
    "stroke_cum = 0\n",
    "stroke_cum_p = 0\n",
    "\n",
    "bal_fs_sum = 0\n",
    "bal_fs_sum_p = 0\n",
    "bal_fs_q = 0\n",
    "\n",
    "vol_wc_cum = 0\n",
    "vol_wc_cum_p = 0\n",
    "\n",
    "advdsp = []\n",
    "date = []\n",
    "\n",
    "nframe = 0\n",
    "\n",
    "balancegrout = 0\n",
    "balancetot = 0\n",
    "\n",
    "\n",
    "###############################################################################################################################\n",
    "\n",
    "\n",
    "for e in np.arange(0,n_row,1):\n",
    "    \n",
    "    if e%dstep==0:    # creo immagine ogni dstep\n",
    "        \n",
    "        try:\n",
    "            ax.clear()\n",
    "            ax0.clear()\n",
    "            ax1.clear()\n",
    "            ax2.clear()\n",
    "            ax3.clear()\n",
    "            ax4.clear()\n",
    "            ax5.clear()\n",
    "            ax6.clear()\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(27,23))\n",
    "        \n",
    "        \n",
    "        gs = fig.add_gridspec(13, 3)\n",
    "        \n",
    "        \n",
    "        ##################################  PRIMO GRAFICO\n",
    "\n",
    "\n",
    "        ax0 = fig.add_subplot(gs[0:2, :])\n",
    "               \n",
    "\n",
    "        ## 1 rett\n",
    "        \n",
    "        if df1['num_corr'][e]!= nseg: \n",
    "            nseg_p = nseg\n",
    "            changepoint = 1\n",
    "            \n",
    "        if df1['num_corr'][e] == nseg: changepoint = 0\n",
    "               \n",
    "        nseg = df1['num_corr'][e]\n",
    "        \n",
    "        ## 2 rett\n",
    "\n",
    "        p_ch8_act = df1.iloc[e,pos_prch08]\n",
    "        p_ch8_max = max(p_ch8_max,df1.iloc[e,pos_prch08])\n",
    "        \n",
    "        p_ch7_act = df1.iloc[e,pos_prch07]\n",
    "        p_ch7_max = max(p_ch7_max,df1.iloc[e,pos_prch07]) \n",
    "        \n",
    "        p_ch6_act = df1.iloc[e,pos_prch06]\n",
    "        p_ch6_max = max(p_ch6_max,df1.iloc[e,pos_prch06])\n",
    "        \n",
    "        p_ch5_act = df1.iloc[e,pos_prch05]\n",
    "        p_ch5_max = max(p_ch5_max,df1.iloc[e,pos_prch05])\n",
    "        \n",
    "        p_ch4_act = df1.iloc[e,pos_prch04]\n",
    "        p_ch4_max = max(p_ch4_max,df1.iloc[e,pos_prch04])\n",
    "        \n",
    "        p_ch3_act = df1.iloc[e,pos_prch03]\n",
    "        p_ch3_max = max(p_ch3_max,df1.iloc[e,pos_prch03])\n",
    "        \n",
    "        p_ch2_act = df1.iloc[e,pos_prch02]\n",
    "        p_ch2_max = max(p_ch2_max,df1.iloc[e,pos_prch02])\n",
    "        \n",
    "        p_ch1_act = df1.iloc[e,pos_prch01]\n",
    "        p_ch1_max = max(p_ch1_max,df1.iloc[e,pos_prch01])\n",
    "        \n",
    "        \n",
    "        ### 3 rett\n",
    "        \n",
    "        feedl = df1.iloc[e,pos_feed]\n",
    "        slurry = df1.iloc[e,pos_slurry]\n",
    "        \n",
    "        bal_fs_q = slurry - feedl\n",
    "        \n",
    "        bal_fs = df1['dvol_bal_feed_slurry[m³]'][e]\n",
    "         \n",
    "        bal_fs_sum = df1['dvol_bal_feed_slurry_cum_seg[m³]'][e]\n",
    "        \n",
    "        \n",
    "        ### 4 rect\n",
    "        \n",
    "        fillev = df1.iloc[e,pos_filllev]\n",
    "        \n",
    "        if e==0: fillev_p = 0\n",
    "        if e!=0: fillev_p = df1.iloc[e-1,pos_filllev]\n",
    "        \n",
    "        \n",
    "        dfillev = fillev-fillev_p\n",
    "        \n",
    "        dvolwch = df1['dvol_work_chamb[m³]'][e]\n",
    "        vol_wc_cum = df1['dvol_work_chamb_cum_seg[m³]'][e]\n",
    "        \n",
    "        ### 5 rect\n",
    "        \n",
    "        stroke = df1['dstroke_pos[mm]'][e]       \n",
    "        stroke_cum = df1['dstroke_cum_seg[mm]'][e]\n",
    "        \n",
    "        dvolteor = df1['dvol_teor[m³]'][e]\n",
    "        vol_teor_cum = df1['dvol_teor_cum_seg[m³]'][e]\n",
    "        \n",
    "        \n",
    "        ###  6 rett \n",
    "        \n",
    "        \n",
    "        if changepoint == 1 : \n",
    "            balancegrout_p = balancegrout\n",
    "            balancetot_p = balancetot\n",
    "        \n",
    "        \n",
    "        balancegrout = df1['dvol_calc_cum_seg[m³]'][e]\n",
    "        balancetot = df1['dvol_teor-calc_cum_seg[m³]'][e]\n",
    "        \n",
    "            \n",
    "        rectangles = {'Info1' : mpl.patches.Rectangle((0,1), 4, 2, color=cmap_segment(nseg%10)),\n",
    "              'Info2'  : mpl.patches.Rectangle((0,4), 4, 6, color=colorstate[df1.state[e]]),\n",
    "                      \n",
    "#             'Info3'   : mpl.patches.Rectangle((5,1), 4, 2, color='grey'),\n",
    "#             'Info4'  : mpl.patches.Rectangle((5,4), 4, 6, color='grey'),\n",
    "                      \n",
    "              'Info3' : mpl.patches.Rectangle((5,1), 4, 2, color=colorbalfs[bal_fs<0]),\n",
    "              'Info4'  : mpl.patches.Rectangle((5,4), 4, 6, color=colorbalfs[bal_fs_q<0]),\n",
    "                      \n",
    "              'Info5'   : mpl.patches.Rectangle((10,1), 4, 2, color=colorbalfs[vol_wc_cum<0]),\n",
    "              'Info6'  : mpl.patches.Rectangle((10,4), 4, 6, color=colorbalfs[bal_fs<0]),\n",
    "                      \n",
    "              'Info7'   : mpl.patches.Rectangle((15,1), 4, 4, color=colorstate[df1.state[e]]),\n",
    "              'Info8'  : mpl.patches.Rectangle((15,6), 4, 4, color=colorstate[df1.state[e]]),\n",
    "              \n",
    "              'Info9'   : mpl.patches.Rectangle((20,1), 4, 4, color=colorbalfs[balancegrout<0]),\n",
    "              'Info10'  : mpl.patches.Rectangle((20,6), 4, 4, color=colorbalfs[balancegrout<0]),              \n",
    "                      \n",
    "              'Info11'   : mpl.patches.Rectangle((25,1), 4, 4, color=colorbalfs[balancetot<0]),\n",
    "              'Info12'  : mpl.patches.Rectangle((25,6), 4, 4, color=colorbalfs[balancetot_p<0])}\n",
    "        \n",
    "        \n",
    "        dict1 = {'Info1': 'Segment {}'.format(int(nseg)),\n",
    "                 'Info2': '{}'.format(df1.state[e]),\n",
    "                 \n",
    "#                'Info3': 'P ch8:{} bar\\nP ch5:{} bar'.format(p_ch8_act,p_ch5_act),\n",
    "#                'Info4': 'Max P ch8:\\n{} bar\\nMax P ch5:\\n{} bar'.format(p_ch8_max,p_ch5_max),\n",
    "                 \n",
    "                 'Info3': 'Volcum:{:.2f}[m³]'.format(bal_fs_sum),\n",
    "                 'Info4': 'Feed:\\n{:.2f}[m³/h]\\nSlurry\\n{:.2f}[m³/h]\\nDiff:{:.1f}[m³/h]\\nDiff:{:.1f}[m³]'.format(feedl,slurry,bal_fs_q,bal_fs),\n",
    "                 \n",
    "                 'Info5': 'Volcum:{:.2f}[m³]'.format(vol_wc_cum),\n",
    "                 'Info6': 'Fill level:\\n{:.2f}[m]\\nFill lev pre\\n{:.2f}[m]\\nDiff:{:.1f}[m]\\nDiff:{:.1f}[m³]'.format(fillev,fillev_p,dfillev,dvolwch),\n",
    "                 \n",
    "                 'Info7': 'Stroke:{:.2f}[mm]\\n Volcum:{:.2f}[m³]'.format(stroke_cum, vol_teor_cum),\n",
    "                 'Info8': 'dStroke:{:.2f}[mm]\\n dVol:{:.2f}[m³]'.format(stroke , dvolteor), \n",
    "                 \n",
    "                 'Info9': 'Balance \\n grout',\n",
    "                 'Info10': 'Bal grout\\n:{:.2f}[m³]'.format(balancegrout),                     \n",
    "                 \n",
    "                 'Info11': 'BAL TOT\\n:{:.2f}[m³]'.format(balancetot),\n",
    "                 'Info12': 'Prev segm:{}[-]\\n BAL TOT PREV:\\n{:.2f}[m³]'.format(nseg_p, balancetot_p),\n",
    "                }\n",
    "\n",
    "\n",
    "        ##########################################################################################\n",
    "        ##################################  RECTANGLES INFO ****************************************\n",
    "        ##########################################################################################\n",
    "        \n",
    "\n",
    "\n",
    "        for r in rectangles:\n",
    "            ax0.add_artist(rectangles[r])\n",
    "            rx, ry = rectangles[r].get_xy()\n",
    "            cx = rx + rectangles[r].get_width()/2.0\n",
    "            cy = ry + rectangles[r].get_height()/2.0\n",
    "\n",
    "            ax0.annotate(dict1[r], (cx, cy), color='w', weight='bold', \n",
    "                        fontsize=15, ha='center', va='center')\n",
    "            \n",
    "    \n",
    "        \n",
    "\n",
    "        ax0.set_xlim((0, 30))\n",
    "        ax0.set_ylim((0, 11))\n",
    "        # ax0.set_aspect('equal')\n",
    "\n",
    "        ax0.axis('off')\n",
    "        \n",
    "        ax0.set_title(str(df1.iloc[e,pos_date]), fontsize = 20.0, pad=0)\n",
    "        \n",
    "        \n",
    "        ##########################################################################################\n",
    "        ##################################  PRIMO GRAFICO ****************************************\n",
    "        ##########################################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        ax = fig.add_subplot(gs[3:6, 1], projection='3d')\n",
    "        ax1 = fig.add_subplot(gs[3:6, 2], projection='3d')\n",
    "        ax4 = fig.add_subplot(gs[3:6, 0])\n",
    "\n",
    "\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"y\") \n",
    "        ax.set_zlabel(\"z\")\n",
    "\n",
    "        ax.view_init(45, -45) # rotazione della vista 3d\n",
    "\n",
    "\n",
    "        \n",
    "        # Strech the graph\n",
    "        ax.get_proj = lambda: np.dot(Axes3D.get_proj(ax), np.diag([1.0, 1.1, 1.0, 1]))\n",
    "\n",
    "        \n",
    "        \n",
    "        #######   GRAFICO A SINISTRA e CENTRALE PRESSURE CHAMBERS  *********\n",
    "\n",
    "\n",
    "        ax.set_xlabel('x'),ax.set_ylabel('Pressure [bar]'),ax.set_zlabel('y')\n",
    "\n",
    "        n_row = df2.shape[0]\n",
    "\n",
    "        for i in np.arange(0,n_sensori,1):\n",
    "\n",
    "            x_ = list_x[i]\n",
    "            z_ = list_z1[i]\n",
    "            y_ = df2.iloc[e,i+1]\n",
    "            c_ = df2.iloc[e,i+10] # fare riga colore per il grafico a barre\n",
    "             \n",
    "\n",
    "            # Plotto una barra per volta\n",
    "            ax.bar3d(x_, y_, z_, dx=0.8, dz=0.8, dy=(0-y_),\n",
    "                    color='deepskyblue')\n",
    "            \n",
    "            ax4.barh(z_, y_, align='center', height=0.4, color=colorrisk[c_])\n",
    "            \n",
    "            ax4.set_xlabel('Pressure [bar]'),ax4.set_ylabel('Distance from center[m]')\n",
    "            ax4.set_title('Pressure [bar]')\n",
    "            ax4.set_xticks\n",
    "            \n",
    "#             ax4.set_yticks\n",
    "#             ax4.set_yticklabels(people)\n",
    "#             \n",
    "#             ax4.set_xlabel('Performance')\n",
    "#             \n",
    "            \n",
    "        ax4.plot((df1.paau_s8[e],df1.paau_s45[e]),(z_s8,z_s4), c='r')\n",
    "        ax4.plot((df1.pau_s8[e],df1.pau_s45[e]),(z_s8,z_s4), c='orange')\n",
    "        ax4.plot((df1.pn_s8[e],df1.pn_s45[e]),(z_s8,z_s4), c='limegreen')\n",
    "        ax4.plot((df1.pal_s8[e],df1.pal_s45[e]),(z_s8,z_s4), c= 'orange')\n",
    "        ax4.plot((df1.paal_s8[e],df1.paal_s45[e]),(z_s8,z_s4), c='r')\n",
    "        \n",
    "        ax4.invert_xaxis()  # labels read top-to-bottom            \n",
    "            \n",
    "        x1_ = 0\n",
    "        z1_ = 0\n",
    "        y1_ = df1.iloc[e, pos_p02]/100\n",
    "            \n",
    "        ax.bar3d(x1_, y1_, z1_, dx=0.9, dz=0.9, dy=(0-y1_), color='red')    \n",
    "        \n",
    "        ax.set_xlim3d([-3.6,3.6])\n",
    "        ax.set_ylim3d([3,0]) # same as saying to invert it \n",
    "        ax.set_zlim3d([-3.6,3.6]) \n",
    "        \n",
    "        # livelli di pressione massimi barre magenta\n",
    "        \n",
    "        ax4.plot([p_ch8_max,p_ch8_max], [2.75,3.05], lw=4, c='m')\n",
    "        ax4.plot([p_ch7_max,p_ch7_max], [1.65,1.95], lw=4, c='m')\n",
    "        ax4.plot([p_ch1_max,p_ch1_max], [1.15,1.45], lw=4, c='m')\n",
    "        ax4.plot([p_ch2_max,p_ch2_max], [0.15,0.45], lw=4, c='m')\n",
    "        ax4.plot([p_ch6_max,p_ch6_max], [-0.75,-0.45], lw=4, c='m')\n",
    "        ax4.plot([p_ch3_max,p_ch6_max], [-1,-1.3], lw=4, c='m')\n",
    "        ax4.plot([p_ch4_max,p_ch4_max], [-2.05,-1.75], lw=4, c='m')\n",
    "        ax4.plot([p_ch5_max,p_ch5_max], [-2.55,-2.25], lw=4, c='m')\n",
    "        \n",
    "        ax4.text(p_ch8_max, 2.8, '{:.2f} '.format(p_ch8_max),horizontalalignment='right', fontdict = font_tx_graph)  \n",
    "        ax4.text(p_ch7_max, 1.8, '{:.2f} '.format(p_ch7_max),horizontalalignment='right', fontdict = font_tx_graph)\n",
    "        ax4.text(p_ch1_max, 1.3, '{:.2f} '.format(p_ch1_max),horizontalalignment='right', fontdict = font_tx_graph)\n",
    "        ax4.text(p_ch2_max, 0.2, '{:.2f} '.format(p_ch2_max),horizontalalignment='right', fontdict = font_tx_graph)\n",
    "        ax4.text(p_ch6_max, -0.7, '{:.2f} '.format(p_ch6_max),horizontalalignment='right', fontdict = font_tx_graph)\n",
    "        ax4.text(p_ch3_max, -1.2, '{:.2f} '.format(p_ch3_max),horizontalalignment='right', fontdict = font_tx_graph)\n",
    "        ax4.text(p_ch4_max, -2.1, '{:.2f} '.format(p_ch4_max),horizontalalignment='right', fontdict = font_tx_graph)    \n",
    "        ax4.text(p_ch5_max, -2.6, '{:.2f} '.format(p_ch5_max),horizontalalignment='right', fontdict = font_tx_graph) \n",
    "        \n",
    "        ax4.text(-0, 2.8, ' C8 {:.2f} bar'.format(df1[cl[pos_prch08]][e]), fontdict = font_tx_graph)  \n",
    "        ax4.text(-0, 1.8, ' C7 {:.2f} bar'.format(df1[cl[pos_prch07]][e]), fontdict = font_tx_graph)\n",
    "        ax4.text(-0, 1.3, ' C1 {:.2f} bar'.format(df1[cl[pos_prch01]][e]), fontdict = font_tx_graph)\n",
    "        ax4.text(-0, 0.2, ' C2 {:.2f} bar'.format(df1[cl[pos_prch02]][e]), fontdict = font_tx_graph)\n",
    "        ax4.text(-0, -0.7, ' C6 {:.2f} bar'.format(df1[cl[pos_prch06]][e]), fontdict = font_tx_graph)\n",
    "        ax4.text(-0, -1.2, ' C3 {:.2f} bar'.format(df1[cl[pos_prch03]][e]), fontdict = font_tx_graph)\n",
    "        ax4.text(-0, -2.1, ' C4 {:.2f} bar'.format(df1[cl[pos_prch04]][e]), fontdict = font_tx_graph)\n",
    "        ax4.text(-0, -2.6, ' C5 {:.2f} bar'.format(df1[cl[pos_prch05]][e]), fontdict = font_tx_graph)\n",
    "            \n",
    "        ############################################\n",
    "        # Plotto la barra rossa FILL LEVEL    ********************************************************\n",
    "        \n",
    "        z1_ = df1.iloc[e,pos_filllev]\n",
    "        \n",
    "        ax1.bar3d(-1, 0, z1_, dx=2, dy=0.5, dz=(-2-z1_),\n",
    "                    color = colorfilllev[df1.iloc[e,pos_filllev]<-1.8])  \n",
    "\n",
    "\n",
    "        x1_ = 0.5\n",
    "        z1_ = 3\n",
    "        y1_ = df1.iloc[e, pos_p01]/100\n",
    "        ax1.bar3d(x1_, y1_, z1_, dx=0.2, dz=0.2, dy=(0-y1_), color='red')       \n",
    "        \n",
    "        x1_ = -0.5\n",
    "        z1_ = 3\n",
    "        y1_ = df1.iloc[e, pos_p05]/100\n",
    "        ax1.bar3d(x1_, y1_, z1_, dx=0.2, dz=0.2, dy=(0-y1_), color='red')  \n",
    "        \n",
    "        ax1.set_xlim3d(-1,1)\n",
    "        ax1.set_ylim3d(2,0) # same as saying to invert it \n",
    "        ax1.set_zlim3d(-2,3) \n",
    "        \n",
    "        \n",
    "        \n",
    "        # ax0.text(0.05, 0.9, str(df2.iloc[e,0]), transform=ax.transAxes, fontdict = fontdict2)  ## data ora\n",
    "        ax1.text2D(0, -0.3, str('Pressure chamber[bar]\\nP0.2[m³/h/100]'), transform=ax.transAxes, fontdict = fontdict2)    \n",
    "        ax1.text2D(-1.2, -0.3, str('Pressure chamber[bar]\\nLimit boundaries[bar]'), transform=ax.transAxes, fontdict = fontdict2)\n",
    "        ax1.text2D(1.5, -0.3, str('Fill Level[m]\\nP0.1,P0.5[m³/h/100]'), transform=ax.transAxes, fontdict = fontdict2)       \n",
    "\n",
    "        \n",
    "        \n",
    "        ##################################  CONTOUR PLOT ##################################################\n",
    "        \n",
    "        ## creo data\n",
    "        \n",
    "                      ## data pressioni\n",
    "        x = list_x\n",
    "        y = list_z\n",
    "        \n",
    "        \n",
    "        \n",
    "        z = [df1[cl[pos_prch01]][e],\n",
    "             df1[cl[pos_prch02]][e],\n",
    "             df1[cl[pos_prch03]][e],\n",
    "             df1[cl[pos_prch04]][e],\n",
    "             df1[cl[pos_prch05]][e],\n",
    "             df1[cl[pos_prch06]][e],\n",
    "             df1[cl[pos_prch07]][e],\n",
    "             df1[cl[pos_prch08]][e]]\n",
    "        \n",
    "                     ## data densità\n",
    "        \n",
    "        x1 = (x[0]+x[7])/2\n",
    "        y1 = (y[0]+y[7])/2\n",
    "        z1 = (z[0]-z[7])/(y[7]-y[0])*10\n",
    "\n",
    "        x2 = (x[6]+x[7])/2\n",
    "        y2 = (y[6]+y[7])/2\n",
    "        z2 = (z[6]-z[7])/(y[7]-y[6])*10\n",
    "\n",
    "        x3 = (x[5]+x[6])/2\n",
    "        y3 = (y[5]+y[6])/2\n",
    "        z3 = (z[5]-z[6])/(y[6]-y[5])*10\n",
    "\n",
    "        x4 = (x[4]+x[5])/2\n",
    "        y4 = (y[4]+y[5])/2\n",
    "        z4 = (z[4]-z[5])/(y[5]-y[4])*10\n",
    "\n",
    "        x5 = (x[3]+x[2])/2\n",
    "        y5 = (y[3]+y[2])/2\n",
    "        z5 = (z[3]-z[2])/(y[2]-y[3])*10\n",
    "\n",
    "        x6 = (x[2]+x[1])/2\n",
    "        y6 = (y[2]+y[1])/2\n",
    "        z6 = (z[2]-z[1])/(y[1]-y[2])*10\n",
    "\n",
    "        x7 = (x[1]+x[0])/2\n",
    "        y7 = (y[1]+y[0])/2\n",
    "        z7 = (z[1]-z[0])/(y[0]-y[1])*10\n",
    "\n",
    "\n",
    "        xd = [x1,x2,x3,x4,x5,x6,x7]\n",
    "        yd = [y1,y2,y3,y4,y5,y6,y7]\n",
    "        zd = [z1,z2,z3,z4,z5,z6,z7]\n",
    "      \n",
    "        \n",
    "        \n",
    "        \n",
    "        #######  1\n",
    "        \n",
    "        ax5 = fig.add_subplot(gs[7:10, 0])   \n",
    "\n",
    "        grid_x, grid_y = np.mgrid[-3.1:3.1:200j, -3.1:3.1:200j]\n",
    "        grid_z2 = griddata((x,y), z, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "        plt.imshow(grid_z2.T, extent=(-3.1,3.1,-3.1,3.1), cmap=plt.cm.rainbow, vmin=df1.paal_s45[e], vmax=df1.paau_s8[e],origin='lower')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        circle1 = plt.Circle((0, 0), 3.1, color=colorstate[df1.state[e]], lw = 5, fill=False)\n",
    "        ax5.add_artist(circle1)\n",
    "        \n",
    "        plt.text(-1.2, -1.7, str('Contour plot pressure chamber[bar]'), transform=ax.transAxes, fontdict = fontdict2)\n",
    "        \n",
    "\n",
    "        #######  2\n",
    "        \n",
    "        ax6 = fig.add_subplot(gs[7:10, 1])\n",
    "        \n",
    "        grid_x, grid_y = np.mgrid[-3.1:3.1:200j, -3.1:3.1:200j]\n",
    "        grid_z3 = griddata((xd,yd), zd, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "        plt.imshow(grid_z3.T, extent=(-3.1,3.1,-3.1,3.1), cmap=plt.cm.rainbow,vmin=1, vmax=1.4,origin='lower')\n",
    "        plt.colorbar()\n",
    "\n",
    "        circle1 = plt.Circle((0, 0), 3.1, color=colorstate[df1.state[e]], lw = 5, fill=False)\n",
    "        ax6.add_artist(circle1)\n",
    "\n",
    "        plt.text(0, -1.7, str('Contour plot density [t/m³]'), transform=ax.transAxes, fontdict = fontdict2)          \n",
    "        \n",
    "        \n",
    "        ##################################  ULTIMO GRAFICO TIME DOMAIN ##################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        ax3 = fig.add_subplot(gs[11:13, :])\n",
    "        \n",
    "        \n",
    "        advdsp.append(df1['dstroke_cum_seg[mm]'][e])\n",
    "        date.append(df1['datestamp'][e])\n",
    "        \n",
    "        y = np.array(advdsp, dtype='int')\n",
    "        x = np.array(date, dtype='datetime64')\n",
    "        \n",
    "        ax3.plot(x,y, label='stroke_cum_seg[mm]')\n",
    "        \n",
    "        # ax3.legend()\n",
    "        \n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "        \n",
    "        # plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "        # ax3.xticks(rotation=70)\n",
    "        # plt.gcf().autofmt_xdate()\n",
    "        \n",
    "        ax3.set_ylim(ymin = 0, ymax=1600)\n",
    "        \n",
    "        startdate = df1.datestamp[e] - timedelta(hours=1)\n",
    "        enddate = df1.datestamp[e] + timedelta(hours=1)    \n",
    "        \n",
    "        ax3.set_xlim(xmin=startdate,xmax=enddate)\n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.text(-1.2, -2.7, str('Stroke [mm] vs time'), transform=ax.transAxes, fontdict = fontdict2)\n",
    "\n",
    "\n",
    "        ##################################  SALVA IMMAGINE ##################################################\n",
    "        \n",
    "        nframe +=1\n",
    "        \n",
    "        nomepng = '{}/{}/img_{:04d}.png'.format(save_folder, gif_filename, nframe)\n",
    "        plt.savefig(nomepng) \n",
    "        \n",
    "        # trick: i use a special name to get the file always updated otherwise the picture is not always the last created\n",
    "        nomepng1 = '{}/{}/img_{:04d}.png?{}'.format(save_folder, gif_filename,nframe,randint(1, 100))   # ?1-100 random  serve per permettere l'update\n",
    "        \n",
    "    \n",
    "        # don't display the static plot...\n",
    "        plt.close()\n",
    "\n",
    "      \n",
    "IPdisplay.Image(url=nomepng1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the static images into a list then save as an animated gif\n",
    "\n",
    "gif_filepath = '{}/{}.gif'.format(save_folder, gif_filename)\n",
    "\n",
    "\n",
    "images = []\n",
    "images = [Image.open(image) for image in glob.glob('{}/*.png'.format(working_folder))]\n",
    "gif = images[0]\n",
    "gif.info['duration'] = 400 #milliseconds per frame\n",
    "gif.info['loop'] = 0 #how many times to loop (0=infinite)\n",
    "append_images=[]\n",
    "gif.save(fp=gif_filepath, format='gif', save_all=True, append_images=images[1:])\n",
    "\n",
    "\n",
    "gif_filepath = '{}/{}.gif?{}'.format(save_folder, gif_filename,randint(1, 100))   # ?1  serve per permettere l'update\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_print = [cl[pos_stroke],cl[pos_advspeed],'dstroke_pos[mm]','dstroke_pos_cum_seg[mm]','num_corr','change','change2','state','state1','state2','state3',cl[pos_filllev],cl[pos_feed],cl[pos_slurry],'vol_teor_cum[m³]','dvol_teor[m³]','dvol_teor_dry[m³]','bal_feed_slurry[m³/h]','dvol_bal_feed_slurry[m³]','dvol_work_chamb[m³]','dvol_calc[m³]','dvol_calc_cum_seg[m³]','dvol_calc_MthE[m³]','dvol_teor_cum_seg[m³]','dvol_calc_MthE_cum_seg[m³]','dvol_teor-calc[m³]']\n",
    "# col_list_print =  [cl[pos_stroke], 'vol_teor_cum[m³]','dvol_teor[m³]']\n",
    "\n",
    "# col_list_print = ['state3','num_corr','theormass1','dtheormass2','theormass2']\n",
    "\n",
    "# dfpar = dfxls[1859:1932][col_list_print]\n",
    "\n",
    "# col_list_print = ['state3','metha1','metha2','metha3','metha']\n",
    "\n",
    "col_list_print = ['dvol_work_chamb[m³]','methd1','methd']\n",
    "\n",
    "dfpar = dfxls[dfxls.num_corr==4205][dfxls.state3==1][col_list_print]\n",
    "\n",
    "dfpar = dfxls[1857:1934][col_list_print]\n",
    "\n",
    "# dfpar.to_excel('dfpar_4205.xls')\n",
    "\n",
    "dfpar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "(dfxls['dvol_teor[m³]']*dfxls['state2']).plot(c='m',label='teor')\n",
    "(dfxls['dvol_calc[m³]']*dfxls['state2']).plot(c='b',label='calc')\n",
    "(dfxls['dvol_bal_feed_slurry[m³]']*dfxls['state2']).plot(c='cyan',label='slurry')\n",
    "(dfxls['dvol_work_chamb[m³]']*dfxls['state2']).plot(c='y',label='workchamb')\n",
    "\n",
    "plt.xlim(1855,1940)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreduced=dfxls.loc[:,[col_list[pos_num],col_list[pos_feed],col_list[pos_slurry],col_list[pos_filllev],'dvol_bal_feed_slurry[m³]','dvol_work_chamb[m³]','dvol_teor[m³]','dvol_calc[m³]','dvol_teor-calc[m³]']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfreduced.groupby(col_list[pos_num]).agg(np.average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.loc[:,[col_list[pos_num],col_list[pos_feed],col_list[pos_slurry],col_list[pos_filllev],'dvol_bal_feed_slurry[m³]','dvol_work_chamb[m³]','dvol_teor[m³]','dvol_calc[m³]','dvol_teor-calc[m³]']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot \"change2\" that detect jump from activity to stop\n",
    "\n",
    "dfxls[dfxls['change2']==True][[col_list[pos_stroke],col_list[pos_num],'change2','change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot \"change\" that detect starts of activity\n",
    "\n",
    "dfxls[dfxls['change']==True].groupby(col_list[pos_num]).agg({col_list[pos_stroke]:min})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.groupby(col_list[pos_num])[col_list[pos_stroke]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "dfxls.groupby('num_corr')[col_list[pos_stroke]].plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prima metti a posto il numero di anello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_g = df.groupby('user')['used']\n",
    "# df['new'] = used_g.cumcount() - used_g.transform(lambda x: (x.values).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "dfxls.groupby('num_corr')['dvol_bal_feed_slurry_cum_seg[m³]'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "(dfxls['dvol_teor[m³]']*dfxls['state2']).plot(c='m',label='teor')\n",
    "(dfxls['dvol_calc[m³]']*dfxls['state2']).plot(c='b',label='calc')\n",
    "(dfxls['dvol_bal_feed_slurry[m³]']*dfxls['state2']).plot(c='cyan',label='slurry')\n",
    "(dfxls['dvol_work_chamb[m³]']*dfxls['state2']).plot(c='y',label='workchamb')\n",
    "(dfxls['dvol_calc_MthE[m³]']).plot(c='g',label='MethE')\n",
    "plt.xlim(1855,1940)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "(dfxls['dvol_teor_cum_seg[m³]']).plot(c='m',label='teor')\n",
    "(dfxls['dvol_calc_cum_seg[m³]']).plot(c='b',label='calc')\n",
    "(dfxls['dvol_bal_feed_slurry_cum_seg[m³]']).plot(c='cyan',label='slurry')\n",
    "(dfxls['dvol_work_chamb_cum_seg[m³]']).plot(c='y',label='workchamb')\n",
    "(dfxls['dvol_calc_MthE_cum_seg[m³]']).plot(c='g',label='MethE')\n",
    "plt.xlim(1858,1930)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'vol_teor_cum[m³]'\n",
    "# #\n",
    "# 'dvol_teor[m³]'\n",
    "# 'dvol_bal_feed_slurry[m³]'    \n",
    "# 'dvol_work_chamb[m³]'\n",
    "# #\n",
    "# 'dvol_calc[m³]'\n",
    "# 'dvol_teor-calc[m³]'\n",
    "\n",
    "\n",
    "# dfxls['dvol_teor_cum_seg[m³]'].plot()\n",
    "dfxls['dvol_bal_feed_slurry_cum_seg[m³]'].plot()\n",
    "dfxls['dvol_work_chamb_cum_seg[m³]'].plot()\n",
    "# dfxls['dvol_calc_cum_seg[m³]'].plot()\n",
    "# dfxls['dvol_teor-calc_cum_seg[m³]'].plot()\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "(dfxls['dvol_teor_cum_seg[m³]']).plot(c='m',label='teor')\n",
    "(dfxls['dvol_calc_cum_seg[m³]']).plot(c='b',label='calc')\n",
    "(dfxls['dvol_bal_feed_slurry_cum_seg[m³]']).plot(c='cyan',label='slurry')\n",
    "(dfxls['dvol_work_chamb_cum_seg[m³]']).plot(c='y',label='workchamb')\n",
    "(dfxls['dvol_calc_MthE_cum_seg[m³]']).plot(c='g',label='MethE')\n",
    "# plt.xlim(1858,1930)\n",
    "plt.xlim(0,1950)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "dfxls['dvol_teor-calc_cum_seg[m³]'].plot(c='m',label='teor')\n",
    "# plt.xlim(1858,1930)\n",
    "plt.xlim(0,1950)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "dfxls[dfxls['num_corr']==4201]['dvol_teor-calc_cum_seg[m³]'].plot(c='b', label='Diff Teor-Calc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_print = [cl[pos_stroke],cl[pos_advspeed],'dstroke_pos[mm]','dstroke_pos_cum_seg[mm]','num_corr','change','change2','state','state1','state2','state3',cl[pos_filllev],cl[pos_feed],cl[pos_slurry],'vol_teor_cum[m³]','dvol_teor[m³]','dvol_teor_dry[m³]','bal_feed_slurry[m³/h]','dvol_bal_feed_slurry[m³]','dvol_work_chamb[m³]','dvol_calc[m³]','dvol_calc_cum_seg[m³]','dvol_calc_MthE[m³]','dvol_teor_cum_seg[m³]','dvol_calc_MthE_cum_seg[m³]','dvol_teor-calc[m³]']\n",
    "# col_list_print =  [cl[pos_stroke], 'vol_teor_cum[m³]','dvol_teor[m³]']\n",
    "\n",
    "# col_list_print = ['state3','num_corr','theormass1','dtheormass2','theormass2']\n",
    "\n",
    "# dfpar = dfxls[1859:1932][col_list_print]\n",
    "\n",
    "col_list_print = ['num_corr','state3','metha1','metha2','metha3','metha']\n",
    "\n",
    "\n",
    "dfpar = dfxls[dfxls.num_corr==4205][dfxls.state3==1][col_list_print]\n",
    "\n",
    "dfpar = dfxls[1857:1934][col_list_print]\n",
    "\n",
    "# dfpar.to_excel('dfpar_4205.xls')\n",
    "\n",
    "dfpar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'vol_teor_cum[m³]'  DO NOT USE\n",
    "# 'vol_teor_cum_dry[m³]' DO NOT USE\n",
    "\n",
    "# 'dstroke_pos_cum_seg[mm]'\n",
    "# 'dvol_teor[m³]'\n",
    "# 'dvol_teor_dry[m³]'\n",
    "# 'dvol_bal_feed_slurry[m³]'      feed-slurry\n",
    "# 'dvol_work_chamb[m³]'           fill\n",
    "# 'dvol_calc[m³]'                 dvol_bal_feed_slurry + dvol_work_chamb\n",
    "# 'dvol_calc_MthE[m³]'\n",
    "# 'dvol_teor-calc[m³]'\n",
    "# 'dvol_teor_cum_seg[m³]'\n",
    "# 'dvol_bal_feed_slurry_cum_seg[m³]'\n",
    "# 'dvol_work_chamb_cum_seg[m³]'\n",
    "# 'dvol_calc_cum_seg[m³]'\n",
    "# 'dvol_teor-calc_cum_seg[m³]'\n",
    "# 'dvol_calc_MthE_cum_seg[m³]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls[dfxls['num_corr']==4205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls = pd.read_hdf('ALL2.h5', key='losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['Groutinjectionquantitycalculatedinm3[m³]']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
