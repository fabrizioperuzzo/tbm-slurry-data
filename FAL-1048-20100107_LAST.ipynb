{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['C:\\\\ProgramData\\\\Anaconda3_1\\\\lib\\\\site-packages\\\\numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6ce380b4c0fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     raise ImportError(\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;34m\"Unable to import required dependencies:\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     )\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdependency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['C:\\\\ProgramData\\\\Anaconda3_1\\\\lib\\\\site-packages\\\\numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['C:\\\\ProgramData\\\\Anaconda3_1\\\\lib\\\\site-packages\\\\numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-88758e3af685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmplot3d\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAxes3D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\pylab.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m from matplotlib.cbook import (\n\u001b[0;32m    143\u001b[0m     MatplotlibDeprecationWarning, dedent, get_label, sanitize_sequence)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mweakref\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWeakMethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;34m\"numpy in {}. One method of fixing this is to repeatedly uninstall \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \"numpy until none is found, then reinstall this version.\")\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumerictypes\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['C:\\\\ProgramData\\\\Anaconda3_1\\\\lib\\\\site-packages\\\\numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version."
     ]
    }
   ],
   "source": [
    "from pylab import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['C:\\\\ProgramData\\\\Anaconda3_1\\\\lib\\\\site-packages\\\\numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-3b9d5d9bfa8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manimation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFuncAnimation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m from matplotlib.cbook import (\n\u001b[0;32m    143\u001b[0m     MatplotlibDeprecationWarning, dedent, get_label, sanitize_sequence)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mweakref\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWeakMethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;34m\"numpy in {}. One method of fixing this is to repeatedly uninstall \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \"numpy until none is found, then reinstall this version.\")\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumerictypes\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['C:\\\\ProgramData\\\\Anaconda3_1\\\\lib\\\\site-packages\\\\numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version."
     ]
    }
   ],
   "source": [
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from images2gif import writeGif\n",
    "import IPython.display as IPdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['C:\\\\ProgramData\\\\Anaconda3_1\\\\lib\\\\site-packages\\\\numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9615c205c8fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# per matrice correlazione\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Scipy helper functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpercentileofscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\seaborn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Capture the original matplotlib rcParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0m_orig_rc_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Import seaborn objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m from matplotlib.cbook import (\n\u001b[0;32m    143\u001b[0m     MatplotlibDeprecationWarning, dedent, get_label, sanitize_sequence)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mweakref\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWeakMethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3_1\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;34m\"numpy in {}. One method of fixing this is to repeatedly uninstall \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \"numpy until none is found, then reinstall this version.\")\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumerictypes\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['C:\\\\ProgramData\\\\Anaconda3_1\\\\lib\\\\site-packages\\\\numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version."
     ]
    }
   ],
   "source": [
    "# per matrice correlazione\n",
    "import seaborn as sns\n",
    "# Scipy helper functions\n",
    "from scipy.stats import percentileofscore\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.tri as mtri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()+'\\\\DATA\\\\20200107'\n",
    "\n",
    "files = []\n",
    "filespath = []\n",
    "# r=root, d=directories, f = files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if r'MERGE' in file:\n",
    "            files.append(file)\n",
    "            filespath.append(os.path.join(r, file))\n",
    "            \n",
    "# since there is only one file I need only the file name\n",
    "os.path.join(r, files[0])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(r, files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4fb33c3869db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfxls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dfxls = pd.read_excel(os.path.join(r, files[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop double columns ending by .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.filter(regex='[.]1$')\n",
    "dfxls = dfxls[dfxls.columns.drop(list(dfxls.filter(regex='[.]1$')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create new columns\n",
    "\n",
    "#### First we create a column that can be detected as date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['datestamp']=pd.to_datetime(dfxls.Date)\n",
    "dfxls['timestamp']=dfxls.datestamp.apply(lambda x: int(time.mktime(x.timetuple())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.sort_values('timestamp',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then we find the position of relevant indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cerco la posizione del fill level\n",
    "\n",
    "pos_filllev=int(dfxls.columns.get_loc(dfxls.filter(regex='(?i)fill.*lev.*work.*chamb').columns.tolist()[0]))\n",
    "pos_stroke=int(dfxls.columns.get_loc(dfxls.filter(regex='(?i)aet.*stroke').columns.tolist()[0]))\n",
    "pos_p01=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)P0.1)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_p02=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)P0.2)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_p03=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)P0.3)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_p04=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)P0.4)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_p05=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)P0.5)(?=.*(?i)Flow)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_pos02=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)posit)(?=.*(?i)2)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_pos03=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)posit)(?=.*(?i)3)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_advspeed=int(dfxls.columns.get_loc(dfxls.filter(regex='(?i)Advance.*speed.*').columns.tolist()[0]))\n",
    "pos_torque=int(dfxls.columns.get_loc(dfxls.filter(regex='(?i)torque.*cutting.*wheel.*').columns.tolist()[0]))\n",
    "pos_feed=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)flow)(?=.*(?i)feed)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_slurry=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)slurry)(?=.*(?i)line)(?=.*(?i)m³/h).*$').columns.tolist()[0]))\n",
    "pos_num=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)1048)(?=.*(?i)advance)(?=.*(?i)[-]).*$').columns.tolist()[0]))\n",
    "pos_prch01=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)1)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch02=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)2)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch03=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)3)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch04=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)4)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch05=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)5)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch06=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)6)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch07=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)7)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_prch08=int(dfxls.columns.get_loc(dfxls.filter(regex='^(?=.*(?i)chamb)(?=.*(?i)8)(?=.*(?i)bar).*$').columns.tolist()[0]))\n",
    "pos_date=int(dfxls.columns.get_loc(dfxls.filter(regex='datestamp').columns.tolist()[0]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list=dfxls.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['datestamp_p'] = dfxls.datestamp.shift(1).copy()\n",
    "# Beign the first row == 0 we need to delete it\n",
    "#dfxls=dfxls.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['datestamp_diff']= dfxls['datestamp']-dfxls['datestamp_p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['datestamp_diff[h]'] = dfxls['datestamp_diff'].astype('timedelta64[s]').copy()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['stroke_diff[mm]'] = 0\n",
    "dfxls['stroke_diff[mm]'] = if dfxls[col_list[pos_stroke]].diff(periods=1) >0 : dfxls[col_list[pos_stroke]].diff(periods=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['stroke_cum[mm]'] = dfxls['stroke_diff[mm]'].sum(periods=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Area_Cutter = 35.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['dVol_Teor[m³]'] = dfxls['stroke_diff[mm]']/1000*Area_Cutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['dVol_Teor_cum[m³]'] = dfxls['stroke_cum[mm]']/1000*Area_Cutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['feed_adj[m³/h]'] = dfxls[col_list[pos_feed]]-dfxls[col_list[pos_pos02]]-dfxls[col_list[pos_pos03]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['bal_feed_slurry[m³/h]']=dfxls[col_list[pos_slurry]]-dfxls['feed_adj[m³/h]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['dVol_bal_feed_slurry[m³]'] = dfxls['bal_feed_slurry[m³/h]']*dfxls['datestamp_diff[h]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcvolume(x):\n",
    "    vol=-0.113*x^5+0.1236*x^4+0.5462*x^3-0.1059*x^2+5.6112*x+11.794\n",
    "    return vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['vol_work_chamb[m³]'] = dfxls[col_list[pos_filllev]].map(lambda x: calcvolume(x))\n",
    "dfxls['vol_work_chamb_diff[m³]'] = dfxls['vol_work_chamb[m³]'].diff(periods=1).copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creo la colonna STATE (fulloper,stall_rotating,stall_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['state']=0\n",
    "f_min_torq25 = dfxls.iloc[:,pos_torque].describe()[4]\n",
    "f_min_adv25 = dfxls.iloc[:,pos_advspeed].describe()[4]\n",
    "\n",
    "dfxls.loc[(dfxls[col_list[pos_torque]]>0) & (dfxls[col_list[pos_advspeed]]>0),'state'] = 'fulloper'\n",
    "dfxls.loc[(dfxls[col_list[pos_torque]]!=0) & (dfxls[col_list[pos_advspeed]]==0),'state'] = 'stall_rotating'\n",
    "dfxls.loc[(dfxls[col_list[pos_torque]]==0) & (dfxls[col_list[pos_advspeed]]==0),'state'] = 'stall_stand'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE col_list for fast individuation of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list=dfxls.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE  H5 FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dfxls.to_hdf('202001_dfxls.h5', key='losses')\n",
    "#dfxls = pd.read_hdf('202001_dfxls.h5', key='losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of chamber columns is: [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "List of interesting columns [0, 2, 3, 4, 5, 6, 7, 8, 9, 32]\n"
     ]
    }
   ],
   "source": [
    "# creo una lista con data, sensori delle camere, fill, \n",
    "list_chamb = []\n",
    "for i in dfxls.filter(regex='Pressure excavation chamber'):\n",
    "    list_chamb.append(dfxls.columns.get_loc(i))\n",
    "print('List of chamber columns is:',list_chamb)\n",
    "\n",
    "list_col = [0]\n",
    "list_col.extend(list_chamb)\n",
    "list_col.append(pos_filllev)\n",
    "print('List of interesting columns',list_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************************************************\n",
    "\n",
    "n_sensori = 8\n",
    "list_x = []\n",
    "list_z = []\n",
    "for i in np.arange(0,n_sensori,1):\n",
    "    x = 1 * np.sin(2*np.pi/8*i)\n",
    "    list_x.append(x)\n",
    "    z = 1 * np.cos(2*np.pi/8*i)\n",
    "    list_z.append(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT SUPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dati = -1   # -1   ## fino a ultima riga\n",
    "\n",
    "df = dfxls.iloc[:num_dati,list_col]\n",
    "n_row = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ************************************************\n",
    "\n",
    "\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "shutil.rmtree('images/gif', ignore_errors=True)\n",
    "save_folder = 'images/gif'\n",
    "gif_filename = '01'\n",
    "\n",
    "working_folder = '{}/{}'.format(save_folder, gif_filename)\n",
    "\n",
    "if not os.path.exists(working_folder):\n",
    "    os.makedirs(working_folder)\n",
    "\n",
    "fontdict1={'fontsize': 18,\n",
    "          'fontweight':0.1,\n",
    "          'horizontalalignment': 'center'}\n",
    "\n",
    "fontdict2 = {'family': 'serif',\n",
    "        'color':  'white',\n",
    "        'weight': 'normal',\n",
    "        'size': 16,\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "colorstate = {'fulloper':'lime','stall_rotating':'yellow','stall_stand':'red'}\n",
    "textstate = {'fulloper':'OPERATION','stall_rotating':'ONLY ROTATING','stall_stand':'STOP'}\n",
    "colorfilllev = {True:'r',False:'b'}\n",
    "colorbalfs = {True:'r',False:'b'}\n",
    "\n",
    "cmap_segment = cm.get_cmap('jet')\n",
    "\n",
    "\n",
    "# Inizializzo le pressioni :\n",
    "\n",
    "p_ch5_max = 0\n",
    "p_ch8_max = 0\n",
    "bal_fs_sum = 0\n",
    "bal_fs_q = 0\n",
    "\n",
    "###############################################################################################################################\n",
    "\n",
    "\n",
    "for e in np.arange(1,n_row,1):\n",
    "    \n",
    "    if e%2==0:    # creo immagine ogni 10 print\n",
    "        \n",
    "        try:\n",
    "            ax.clear()\n",
    "            ax0.clear()\n",
    "            ax1.clear()\n",
    "            ax2.clear()\n",
    "            ax3.clear()\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        fig = plt.figure(figsize=(18,18))\n",
    "        \n",
    "        \n",
    "        gs = fig.add_gridspec(5, 2)\n",
    "        \n",
    "        \n",
    "        ##################################  PRIMO GRAFICO\n",
    "\n",
    "\n",
    "        ax0 = fig.add_subplot(gs[0, :])\n",
    "        \n",
    "        \n",
    "               \n",
    "\n",
    "        rectangles = {'Info1' : mpl.patches.Rectangle((2,1), 6, 2, color=cmap_segment(dfxls.iloc[e,pos_num]%10)),\n",
    "                      'Info2'  : mpl.patches.Rectangle((2,4), 6, 6, color=colorstate[dfxls.state[e]]),\n",
    "                      'Info3'   : mpl.patches.Rectangle((9,1), 4, 2, color='grey'),\n",
    "                      'Info4'  : mpl.patches.Rectangle((9,4), 4, 6, color='grey'),\n",
    "                      'Info5' : mpl.patches.Rectangle((14,1), 4, 2, color=colorbalfs[bal_fs<0]),\n",
    "                      'Info6'  : mpl.patches.Rectangle((14,4), 4, 6, color=colorbalfs[bal_fs_q<0]),\n",
    "                      'Info7'   : mpl.patches.Rectangle((19,1), 4, 2),\n",
    "                      'Info8'  : mpl.patches.Rectangle((19,4), 4, 6),\n",
    "                      'Info9'   : mpl.patches.Rectangle((24,1), 4, 2),\n",
    "                      'Info10'  : mpl.patches.Rectangle((24,4), 4, 6)}\n",
    "\n",
    "        p_ch5_act = dfxls.iloc[e,pos_prch05]\n",
    "        p_ch5_max = max(p_ch5_max,dfxls.iloc[e,pos_prch05])\n",
    "        p_ch8_act = dfxls.iloc[e,pos_prch08]\n",
    "        p_ch8_max = max(p_ch8_max,dfxls.iloc[e,pos_prch08])\n",
    "        \n",
    "        feedl = dfxls.iloc[e,pos_feed]\n",
    "        slurry = dfxls.iloc[e,pos_slurry]\n",
    "        \n",
    "        bal_fs_q = slurry - feedl\n",
    "        \n",
    "        bal_fs = dfxls['dVol_bal_feed_slurry[m³]'][e]\n",
    "        \n",
    "        bal_fs_sum += bal_fs\n",
    "        \n",
    "        if dfxls.iloc[e,pos_num] != dfxls.iloc[e-1,pos_num]: \n",
    "            bal_fs_sum = 0\n",
    "        \n",
    "        \n",
    "        dict1 = {'Info1': 'Segment {}'.format(dfxls.iloc[e,pos_num]),\n",
    "                 'Info2': '{}'.format(dfxls.state[e]),\n",
    "                 'Info3': 'P ch8:{} bar\\nP ch5:{} bar'.format(p_ch8_act,p_ch5_act),\n",
    "                 'Info4': 'Max P ch8:\\n{} bar\\nMax P ch5:\\n{} bar'.format(p_ch8_max,p_ch5_max),\n",
    "                 'Info5': 'Bal:{:.2f}[m³]'.format(bal_fs_sum),\n",
    "                 'Info6': 'Feed:\\n{:.2f}[m³/h]\\nSlurry\\n{:.2f}[m³/h]\\nBalance:\\n{:.2f}[m³/h]'.format(feedl,slurry,bal_fs_q),\n",
    "                 'Info7': 'Pressure: {}'.format(55),\n",
    "                 'Info8': 'Pressure: {}'.format(55),\n",
    "                 'Info9': 'Pressure: {}'.format(55),\n",
    "                 'Info10': 'Pressure: {}'.format(55), \n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for r in rectangles:\n",
    "            ax0.add_artist(rectangles[r])\n",
    "            rx, ry = rectangles[r].get_xy()\n",
    "            cx = rx + rectangles[r].get_width()/2.0\n",
    "            cy = ry + rectangles[r].get_height()/2.0\n",
    "\n",
    "            ax0.annotate(dict1[r], (cx, cy), color='w', weight='bold', \n",
    "                        fontsize=14, ha='center', va='center')\n",
    "\n",
    "        ax0.set_xlim((0, 30))\n",
    "        ax0.set_ylim((0, 11))\n",
    "        # ax0.set_aspect('equal')\n",
    "\n",
    "        ax0.axis('off')\n",
    "        \n",
    "        \n",
    "        ##################################  PRIMO GRAFICO ****************************************\n",
    "        \n",
    "        ax = fig.add_subplot(gs[1:3, 0], projection='3d')\n",
    "        ax1 = fig.add_subplot(gs[1:3, 1], projection='3d')\n",
    "        \n",
    "\n",
    "\n",
    "        ax.set_xlabel(\"x\")\n",
    "        ax.set_ylabel(\"y\") \n",
    "        ax.set_zlabel(\"z\")\n",
    "\n",
    "        ax.view_init(45, -45) # rotazione della vista 3d\n",
    "\n",
    "        ax.set_xlim3d([-1,1])\n",
    "        ax.set_ylim3d([3,0]) # same as saying to invert it \n",
    "        ax.set_zlim3d([-1,1]) \n",
    "        \n",
    "        # Strech the graph\n",
    "        ax.get_proj = lambda: np.dot(Axes3D.get_proj(ax), np.diag([1.0, 1.1, 1.0, 1]))\n",
    "\n",
    "        #######      *********\n",
    "\n",
    "\n",
    "        ax.set_xlabel('x'),ax.set_ylabel('Pressure [bar]'),ax.set_zlabel('y')\n",
    "\n",
    "        n_row = df.shape[0]\n",
    "\n",
    "        for i in np.arange(0,n_sensori,1):\n",
    "\n",
    "            x_ = list_x[i]\n",
    "            z_ = list_z[i]\n",
    "            y_ = df.iloc[e,i+1]\n",
    "             \n",
    "\n",
    "            # Plotto una barra per volta\n",
    "            ax.bar3d(x_, y_, z_, dx=0.2, dz=0.2, dy=(0-y_),\n",
    "                    color='deepskyblue')\n",
    "            \n",
    "        x1_ = 0\n",
    "        z1_ = 0\n",
    "        y1_ = dfxls.iloc[e, pos_p02]/100\n",
    "            \n",
    "        ax.bar3d(x1_, y1_, z1_, dx=0.2, dz=0.2, dy=(0-y1_), color='red')    \n",
    "            \n",
    "            \n",
    "\n",
    "        # Plotto la barra rossa FILL LEVEL    ********************************************************\n",
    "        \n",
    "        z1_ = dfxls.iloc[e,pos_filllev]\n",
    "        \n",
    "        ax1.bar3d(-1, 0, z1_, dx=2, dy=0.5, dz=(-2-z1_),\n",
    "                    color = colorfilllev[dfxls.iloc[e,pos_filllev]<-1.8])  \n",
    "        \n",
    "\n",
    "\n",
    "        x1_ = 0.5\n",
    "        z1_ = 3\n",
    "        y1_ = dfxls.iloc[e, pos_p01]/100\n",
    "        ax1.bar3d(x1_, y1_, z1_, dx=0.2, dz=0.2, dy=(0-y1_), color='red')       \n",
    "        \n",
    "        x1_ = -0.5\n",
    "        z1_ = 3\n",
    "        y1_ = dfxls.iloc[e, pos_p05]/100\n",
    "        ax1.bar3d(x1_, y1_, z1_, dx=0.2, dz=0.2, dy=(0-y1_), color='red')  \n",
    "        \n",
    "        ax1.set_xlim3d(-1,1)\n",
    "        ax1.set_ylim3d(2,0) # same as saying to invert it \n",
    "        ax1.set_zlim3d(-2,3) \n",
    "        \n",
    "        \n",
    "        \n",
    "        ax.text2D(0.05, 0.99, str(df.iloc[e,0]), transform=ax.transAxes, fontdict = fontdict2)\n",
    "\n",
    "        ax.text2D(0, -0.3, str('Pressure chamber[bar]\\nP0.2[m³/h/100]'), transform=ax.transAxes, fontdict = fontdict2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ax1.text2D(1.5, -0.3, str('Fill Level[m]\\nP0.1,P0.5[m³/h/100]'), transform=ax.transAxes, fontdict = fontdict2)\n",
    "        \n",
    "\n",
    "    \n",
    "        plt.savefig('{}/{}/img{:04d}.png'.format(save_folder, gif_filename, e))         \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##################################  ULTIMO GRAFICO ##################################################\n",
    "        \n",
    "        \n",
    "        ax3 = fig.add_subplot(gs[4, :])\n",
    "        \n",
    "        advdsp = dfxls.iloc[e,pos_advspeed]\n",
    "        date = dfxls.iloc[e,pos_date]\n",
    "        \n",
    "        ax3.plot(date,advdsp, label='advance speed')\n",
    "        \n",
    "        ax3.xlim = (dfxls.datestamp.min(),dfxls.datestamp.max())\n",
    "        ax3.xlim = (dfxls[col_list[pos_advspeed]].min(),dfxls[col_list[pos_advspeed]].max())\n",
    "        \n",
    "        ax3.legend()\n",
    "    \n",
    "        # don't display the static plot...\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      2020-01-07 07:00:30\n",
       "2      2020-01-07 07:01:00\n",
       "3      2020-01-07 07:01:30\n",
       "4      2020-01-07 07:02:00\n",
       "5      2020-01-07 07:02:30\n",
       "               ...        \n",
       "2875   2020-01-08 06:57:30\n",
       "2876   2020-01-08 06:58:00\n",
       "2877   2020-01-08 06:58:30\n",
       "2878   2020-01-08 06:59:00\n",
       "2879   2020-01-08 06:59:30\n",
       "Name: datestamp, Length: 2879, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfxls.iloc[:,pos_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the static images into a list then save as an animated gif\n",
    "gif_filepath = '{}/{}.gif'.format(save_folder, gif_filename)\n",
    "\n",
    "\n",
    "images = []\n",
    "images = [Image.open(image) for image in glob.glob('{}/*.png'.format(working_folder))]\n",
    "gif = images[0]\n",
    "gif.info['duration'] = 400 #milliseconds per frame\n",
    "gif.info['loop'] = 0 #how many times to loop (0=infinite)\n",
    "append_images=[]\n",
    "gif.save(fp=gif_filepath, format='gif', save_all=True, append_images=images[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9962e6d99846>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\fpe\\\\JUPYTER\\\\datimacchina'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msave_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'images/gif'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\fpe\\\\JUPYTER\\\\datimacchina')\n",
    "save_folder = 'images/gif'\n",
    "gif_filename = '01'\n",
    "\n",
    "image_folder = '{}/{}'.format(save_folder, gif_filename)  # 'images/gif/01'\n",
    "video_name = 'video.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, fps=4, frameSize=(width,height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_filepath = '{}/{}.gif?{}'.format(save_folder, gif_filename,randint(1, 100))   # ?1  serve per permettere l'update\n",
    "IPdisplay.Image(url=gif_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\fpe\\\\JUPYTER\\\\datimacchina'"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,n_sensori,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,10))\n",
    "# ax = fig.add_subplot(111)\n",
    "\n",
    "y_=[]\n",
    "\n",
    "e = 100\n",
    "\n",
    "for i in np.arange(0,n_sensori,1):  # array([0, 1, 2, 3, 4, 5, 6, 7])\n",
    "    \n",
    "    y_.append(float(df.iloc[e,i+1]))\n",
    "   \n",
    "xc=[]\n",
    "zc=[]\n",
    "\n",
    "for i in np.linspace(0,359,360):\n",
    "    \n",
    "    xc.append(0.5*np.sin(np.deg2rad(i)))\n",
    "    zc.append(0.5*np.cos(np.deg2rad(i)))\n",
    "    \n",
    "    xc.append(1.5*np.sin(np.deg2rad(i)))\n",
    "    zc.append(1.5*np.cos(np.deg2rad(i)))\n",
    "    \n",
    "    \n",
    "\n",
    "x_ = list_x.copy()\n",
    "z_ = list_z.copy()\n",
    "\n",
    "x_.extend((np.ones(21)*2).tolist())\n",
    "z_.extend(np.linspace(-2,2,21).tolist())\n",
    "\n",
    "x_.extend((np.ones(21)*-2).tolist())\n",
    "z_.extend(np.linspace(-2,2,21).tolist())\n",
    "\n",
    "x_.extend(np.linspace(-1.9,1.9,19).tolist())\n",
    "z_.extend((np.ones(19)*2).tolist())\n",
    "\n",
    "x_.extend(np.linspace(-1.9,1.9,19).tolist())\n",
    "z_.extend((np.ones(19)*-2).tolist())\n",
    "\n",
    "x_.extend(xc)\n",
    "z_.extend(zc)\n",
    "\n",
    "y_.extend(np.zeros(80+720).tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Z = np.meshgrid(x_, z_, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "Ti = griddata((x_, z_), y_, (X, Z), method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.contourf(X, Y, Ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.tri as mtri\n",
    "triang = mtri.Triangulation(x_, z_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.triplot(triang, c=\"#D3D3D3\", marker='.', markerfacecolor=\"#DC143C\", markeredgecolor=\"black\", markersize=10)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triang.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,12))\n",
    "ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "\n",
    "ax.plot_trisurf(triang.y, triang.x, y_, cmap='Blues')\n",
    "\n",
    "ax.view_init(elev=50, azim=45)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.contourf(triang.y, triang.x, np.array(y_), cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfg = dfxls.iloc[:,[2,4,6,9,10,11,19,20,22,26,27,30,32,33,34,37,50,51]]\n",
    "dfg = dfxls.iloc[:,[2,4,6,9,10,11,19,20,22,26,27,30,32]]\n",
    "dfg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficient\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .6), xycoords=ax.transAxes,\n",
    "               size = 20)\n",
    "    \n",
    "plt.style.use('seaborn-pastel')   \n",
    "sns.set_style(\"white\")\n",
    "    \n",
    "cmap = sns.cubehelix_palette(light=1, dark = 0.1,\n",
    "                             hue = 0.5, as_cmap=True)\n",
    "\n",
    "sns.set_context(font_scale=2)\n",
    "\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "sns.set(rc={'figure.figsize':(30,30)})\n",
    "\n",
    "\n",
    "# Pair grid set up\n",
    "g = sns.PairGrid(dfg)\n",
    "\n",
    "# Scatter plot on the upper triangle\n",
    "g.map_upper(plt.scatter, s=10, color = 'b')\n",
    "\n",
    "# Distribution on the diagonal\n",
    "g.map_diag(sns.distplot, kde=False, color = 'red')\n",
    "\n",
    "# Density Plot and Correlation coefficients on the lower triangle\n",
    "g.map_lower(sns.kdeplot, cmap = cmap)\n",
    "g.map_lower(corrfunc);\n",
    "\n",
    "plt.savefig('{}/{}/img_{}.png'.format(save_folder, gif_filename, 'corr_matrix'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creo una funzione per plottare in automatico il multigrafico di correlazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrfunc(x, y, **kws):\n",
    "    r, _ = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "                xy=(.1, .6), xycoords=ax.transAxes,\n",
    "               size = 20)\n",
    "\n",
    "def corrgraph(dfg, nomefile):\n",
    "    # Function to create graph correlation matrix\n",
    "\n",
    "    plt.style.use('seaborn-pastel')   \n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    cmap = sns.cubehelix_palette(light=1, dark = 0.1,\n",
    "                                 hue = 0.5, as_cmap=True)\n",
    "\n",
    "    sns.set_context(font_scale=2)\n",
    "\n",
    "    fig = plt.figure(figsize=(30,30))\n",
    "    sns.set(rc={'figure.figsize':(30,30)})\n",
    "\n",
    "\n",
    "    # Pair grid set up\n",
    "    g = sns.PairGrid(dfg)\n",
    "\n",
    "    # Scatter plot on the upper triangle\n",
    "    g.map_upper(plt.scatter, s=10, color = 'b')\n",
    "\n",
    "    # Distribution on the diagonal\n",
    "    g.map_diag(sns.distplot, kde=False, color = 'red')\n",
    "\n",
    "    # Density Plot and Correlation coefficients on the lower triangle\n",
    "    g.map_lower(sns.kdeplot, cmap = cmap)\n",
    "    g.map_lower(corrfunc);\n",
    "\n",
    "    plt.savefig('{}/{}/img_{}.png'.format(save_folder, gif_filename, nomefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotto il multigrafico per i dati delle pressure chamber e il Fill level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls.filter(regex='(Pressure excavation chamber|Fill level)')\n",
    "\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "dfg.columns = col_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrgraph(dfg, 'corr_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10,8))\n",
    "corr = dfg.corr()\n",
    "sns.heatmap(corr,\n",
    "           xticklabels=corr.columns.values,\n",
    "           yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Seleziono colonne utili\n",
    "\n",
    "dfg=dfxls.filter(regex='(Pressure excavation chamber 5|Pressure excavation chamber 8|Fill level|grout injection pressure|\\\n",
    "grout injection amount|grout injection flow|Air Flow in Normal)')\n",
    "\n",
    "# Semplifico il nome delle colonne\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Air Flow in Normal m3/min\",\"Air_Flow_in\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\" grout injection \",\"_Gr_in_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"pressure\",\"Pr\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Line \",\"L_\"),col_ls))\n",
    "dfg.columns = col_ls\n",
    "\n",
    "# Verifico i risultati dell'operazione\n",
    "col_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrgraph(dfg, 'corr_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Seleziono colonne utili\n",
    "\n",
    "dfg=dfxls.filter(regex='(Pressure excavation chamber 5|Pressure excavation chamber 8|Fill level|grout injection pressure|\\\n",
    "Line 1 grout injection amount|Line 1 grout injection flow)')\n",
    "\n",
    "# Semplifico il nome delle colonne\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Air Flow in Normal m3/min\",\"Air_Flow_in\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Line 1 grout injection \",\"L1_Gr_in_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"pressure\",\"Pr\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Line \",\"L_\"),col_ls))\n",
    "dfg.columns = col_ls\n",
    "\n",
    "# Verifico i risultati dell'operazione\n",
    "col_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrgraph(dfg, 'corr_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "import statsmodels as sm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 12.0)\n",
    "#matplotlib.style.use('ggplot')\n",
    "\n",
    "# Create models from data\n",
    "def best_fit_distribution(data, bins=10, ax=None):\n",
    "    \"\"\"Model data by finding best fit distribution to data\"\"\"\n",
    "    # Get histogram of original data\n",
    "    y, x = np.histogram(data, bins=bins, density=True)\n",
    "    x = (x + np.roll(x, -1))[:-1] / 2.0\n",
    "\n",
    "    # Distributions to check\n",
    "    DISTRIBUTIONS = [        \n",
    "        st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,\n",
    "        st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,\n",
    "        st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,\n",
    "        st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,\n",
    "        st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,\n",
    "        st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,\n",
    "        st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,\n",
    "        st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,\n",
    "        st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,\n",
    "        st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy]\n",
    "\n",
    "\n",
    "    # Best holders\n",
    "    best_distribution = st.norm\n",
    "    best_params = (0.0, 1.0)\n",
    "    best_sse = np.inf\n",
    "\n",
    "    # Estimate distribution parameters from data\n",
    "    for distribution in DISTRIBUTIONS:\n",
    "\n",
    "        # Try to fit the distribution\n",
    "        try:\n",
    "            # Ignore warnings from data that can't be fit\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore')\n",
    "\n",
    "                # fit dist to data\n",
    "                params = distribution.fit(data)\n",
    "\n",
    "                # Separate parts of parameters\n",
    "                arg = params[:-2]\n",
    "                loc = params[-2]\n",
    "                scale = params[-1]\n",
    "\n",
    "                # Calculate fitted PDF and error with fit in distribution\n",
    "                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n",
    "                sse = np.sum(np.power(y - pdf, 2.0))\n",
    "\n",
    "                # if axis pass in add to plot\n",
    "                try:\n",
    "                    if ax:\n",
    "                        pd.Series(pdf, x).plot(ax=ax)\n",
    "                    end\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                # identify if this distribution is better\n",
    "                if best_sse > sse > 0:\n",
    "                    best_distribution = distribution\n",
    "                    best_params = params\n",
    "                    best_sse = sse\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return (best_distribution.name, best_params)\n",
    "\n",
    "def make_pdf(dist, params, size=10000):\n",
    "    \"\"\"Generate distributions's Probability Distribution Function \"\"\"\n",
    "\n",
    "    # Separate parts of parameters\n",
    "    arg = params[:-2]\n",
    "    loc = params[-2]\n",
    "    scale = params[-1]\n",
    "\n",
    "    # Get sane start and end points of distribution\n",
    "    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n",
    "    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n",
    "\n",
    "    # Build PDF and turn into pandas Series\n",
    "    x = np.linspace(start, end, size)\n",
    "    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n",
    "    pdf = pd.Series(y, x)\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###     CREATE LAST DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Seleziono colonne utili\n",
    "\n",
    "dfg=dfxls.filter(regex='(Pressure excavation chamber 5|Pressure excavation chamber 8|Fill level|grout injection pressure|\\\n",
    "Line 1 grout injection amount|Line 1 grout injection flow)')\n",
    "\n",
    "# Semplifico il nome delle colonne\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Air Flow in Normal m3/min\",\"Air_Flow_in\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Line 1 grout injection \",\"L1_Gr_in_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"pressure\",\"Pr\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Line \",\"L_\"),col_ls))\n",
    "dfg.columns = col_ls\n",
    "\n",
    "# Verifico i risultati dell'operazione\n",
    "print (col_ls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from statsmodels datasets plot best fit distribution\n",
    "\n",
    "#data = pd.Series(sm.datasets.elnino.load_pandas().data.set_index('YEAR').values.ravel())\n",
    "\n",
    "dfg_1 = dfg.copy() # .copy() avoid regressive modifications\n",
    "\n",
    "n_cols = dfg_1.shape[1]\n",
    "\n",
    "for e in np.arange(0,n_cols,1):\n",
    "\n",
    "    data = dfg_1.iloc[:,e].dropna().reset_index().copy()\n",
    "    data =pd.Series(data.values.ravel())\n",
    "\n",
    "\n",
    "    # Plot for comparison\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = data.plot(kind='hist', bins=10, normed=True, alpha=0.5)\n",
    "    # Save plot limits\n",
    "    dataYLim = ax.get_ylim()\n",
    "\n",
    "    # Find best fit distribution\n",
    "    best_fit_name, best_fit_params = best_fit_distribution(data, 200, ax)\n",
    "    best_dist = getattr(st, best_fit_name)\n",
    "\n",
    "    # Update plots\n",
    "    ax.set_ylim(dataYLim)\n",
    "    ax.set_title(dfg_1.columns[e] + u'\\n All Fitted Distributions')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "    # Make PDF with best params \n",
    "    pdf = make_pdf(best_dist, best_fit_params)\n",
    "\n",
    "    # Display\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = pdf.plot(lw=2, label='PDF', legend=True)\n",
    "    data.plot(kind='hist', bins=10, normed=True, alpha=0.5, label='Data', legend=True, ax=ax)\n",
    "\n",
    "    param_names = (best_dist.shapes + ', loc, scale').split(', ') if best_dist.shapes else ['loc', 'scale']\n",
    "    param_str = ', '.join(['{}={:0.2f}'.format(k,v) for k,v in zip(param_names, best_fit_params)])\n",
    "    dist_str = '{}({})'.format(best_fit_name, param_str)\n",
    "\n",
    "    ax.set_title(dfg_1.columns[e] + u'\\n' + dist_str)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotto il grafico multiplo di correlazione\n",
    "\n",
    "corrgraph(dfg, 'corr_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Seleziono colonne utili\n",
    "\n",
    "dfg=dfxls.filter(regex='(Pressure excavation chamber 5|Pressure excavation chamber 8|Fill level|grout injection pressure|\\\n",
    "Line 1 grout injection amount|Line 1 grout injection flow)')\n",
    "\n",
    "# Semplifico il nome delle colonne\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Air Flow in Normal m3/min\",\"Air_Flow_in\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Line 1 grout injection \",\"L1_Gr_in_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"pressure\",\"Pr\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Line \",\"L_\"),col_ls))\n",
    "dfg.columns = col_ls\n",
    "\n",
    "# Verifico i risultati dell'operazione\n",
    "print (col_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###      SALVA IL DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "dfxls.to_hdf('20200107.h5', key='losses')\n",
    "dfxls.to_hdf('20200107.h5', key='losses')\n",
    "dfxls_hdf = pd.read_hdf('20200107.h5', key='losses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###          TROVA LE DISTRIBUZIONI DELLA Working Chamber 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls.filter(regex='(Pressure excavation chamber 5)')\n",
    "X=np.array(dfg.iloc[:,0]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 3\n",
    "g = mixture.GaussianMixture(n_components=n_comp,covariance_type='full')\n",
    "g.fit(X)\n",
    "weights = g.weights_\n",
    "means = g.means_\n",
    "covars = g.covariances_\n",
    "#  Plotta le distribuzioni\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.hist(X, bins=100, histtype='bar', density=True, ec='red', alpha=0.5)\n",
    "\n",
    "f_axis = X.copy().ravel()\n",
    "f_axis.sort()\n",
    "\n",
    "for i in np.arange(0,n_comp,1):\n",
    "    plt.plot(f_axis,weights[i]*stats.norm.pdf(f_axis,means[i],np.sqrt(covars[i])).ravel(), c='red')\n",
    "\n",
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = g.predict(X)\n",
    "Y=np.array(dfg.index)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.scatter(Y,X[:, 0], c=labels, s=10, cmap='viridis')\n",
    "plt.legend(loc='upper left', frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Seleziono colonne utili\n",
    "\n",
    "dfg=dfxls.filter(regex='(Pressure excavation chamber 5|Pressure excavation chamber 8|Fill level|grout injection pressure|\\\n",
    "Line 1 grout injection amount|Line 1 grout injection flow)')\n",
    "\n",
    "# Semplifico il nome delle colonne\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Air Flow in Normal m3/min\",\"Air_Flow_in\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Line 1 grout injection \",\"L1_Gr_in_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"pressure\",\"Pr\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Line \",\"L_\"),col_ls))\n",
    "dfg.columns = col_ls\n",
    "\n",
    "# Verifico i risultati dell'operazione\n",
    "print (col_ls)\n",
    "\n",
    "dfg['classi']=labels\n",
    "dfg=dfg[dfg.classi==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotto il grafico multiplo di correlazione\n",
    "\n",
    "corrgraph(dfg, 'corr_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls.filter(regex='(Pressure excavation chamber|Fill level)')\n",
    "\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "dfg.columns = col_ls\n",
    "dfg['classi']=labels\n",
    "dfg=dfg[dfg.classi==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotto il grafico multiplo di correlazione\n",
    "\n",
    "corrgraph(dfg, 'corr_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TROVA LE DISTRIBUZIONI DELLA Working Chamber 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls.filter(regex='(Pressure excavation chamber 4)')\n",
    "X=np.array(dfg.iloc[:,0]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 3\n",
    "g = mixture.GaussianMixture(n_components=n_comp,covariance_type='full')\n",
    "g.fit(X)\n",
    "weights = g.weights_\n",
    "means = g.means_\n",
    "covars = g.covariances_\n",
    "#  Plotta le distribuzioni\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.hist(X, bins=100, histtype='bar', density=True, ec='red', alpha=0.5)\n",
    "\n",
    "f_axis = X.copy().ravel()\n",
    "f_axis.sort()\n",
    "\n",
    "for i in np.arange(0,n_comp,1):\n",
    "    plt.plot(f_axis,weights[i]*stats.norm.pdf(f_axis,means[i],np.sqrt(covars[i])).ravel(), c='red')\n",
    "\n",
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, covars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = g.predict(X)\n",
    "Y=np.array(dfg.index)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.scatter(Y,X[:, 0], c=labels, s=10, cmap='viridis')\n",
    "plt.legend(loc='upper left', frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls.filter(regex='(Pressure excavation chamber|Fill level)')\n",
    "\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "dfg.columns = col_ls\n",
    "dfg['classi']=labels\n",
    "dfg=dfg[dfg.classi==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro: \n",
    "- Advance speed [mm/min] = 0\n",
    "- Torque cutting wheel [MNm] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.describe()['Advance speed [mm/min]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.describe()['Torque cutting wheel [MNm]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfg=dfxls[(dfxls['Torque cutting wheel [MNm]']==0) & (dfxls['Advance speed [mm/min]']==0)].filter(regex='(Pressure excavation chamber|Fill level)')\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "dfg.columns = col_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotto il grafico multiplo di correlazione\n",
    "\n",
    "corrgraph(dfg.loc[:, dfg.columns != 'classi'], 'corr_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro:\n",
    "- Advance speed [mm/min] = 0\n",
    "- Torque cutting wheel [MNm] # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls[(dfxls['Torque cutting wheel [MNm]']!=0) & (dfxls['Advance speed [mm/min]']==0)].filter(regex='(Pressure excavation chamber|Fill level)')\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "dfg.columns = col_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotto il grafico multiplo di correlazione\n",
    "\n",
    "corrgraph(dfg.loc[:, dfg.columns != 'classi'], 'corr_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro:\n",
    "- Advance speed [mm/min] # 0\n",
    "- Torque cutting wheel [MNm] # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls[(dfxls['Torque cutting wheel [MNm]']!=0) & (dfxls['Advance speed [mm/min]']!=0)].filter(regex='(Pressure excavation chamber|Fill level)')\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "dfg.columns = col_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotto il grafico multiplo di correlazione\n",
    "\n",
    "corrgraph(dfg.loc[:, dfg.columns != 'classi'], 'corr_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot only inside 95 and  5% confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls[(dfxls['Torque cutting wheel [MNm]']!=0) & (dfxls['Advance speed [mm/min]']!=0)]\n",
    "dfg.describe()['Torque cutting wheel [MNm]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls[(dfxls['Torque cutting wheel [MNm]']!=0) & (dfxls['Advance speed [mm/min]']!=0)]\n",
    "dfg.describe()['Advance speed [mm/min]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo gli intervallli di confidenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import scipy.stats\n",
    "\n",
    "dfg=dfxls[(dfxls['Torque cutting wheel [MNm]']!=0) & (dfxls['Advance speed [mm/min]']!=0)]\n",
    "\n",
    "mean = dfg.mean()\n",
    "std = dfg.std()\n",
    "\n",
    "n= dfg.shape[0]\n",
    "f_inf = std / np.sqrt(n) * stats.t.ppf(1-0.25/2, n - 1)\n",
    "f_sup = std / np.sqrt(n) * stats.t.ppf(1-0.25/2, n - 1)\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "f_inf_torq=mean_confidence_interval(dfg['Torque cutting wheel [MNm]'],0.9)[1]\n",
    "f_sup_torq=mean_confidence_interval(dfg['Torque cutting wheel [MNm]'],0.9)[2]\n",
    "f_inf_adv=mean_confidence_interval(dfg['Advance speed [mm/min]'],0.9)[1]\n",
    "f_sup_adv=mean_confidence_interval(dfg['Advance speed [mm/min]'],0.9)[2]\n",
    "\n",
    "f_min_torq = dfg['Torque cutting wheel [MNm]'].min()\n",
    "f_min_adv = dfg['Advance speed [mm/min]'].min()\n",
    "\n",
    "f_min_torq25 = dfg.describe()['Torque cutting wheel [MNm]'][4]\n",
    "f_min_adv25 = dfg.describe()['Advance speed [mm/min]'][4]\n",
    "\n",
    "dfg.describe()['Advance speed [mm/min]']\n",
    "print('dfg shape {}'.format(dfg.shape))\n",
    "print('Torque cutting wheel [MNm]: {}'.format(f_inf_torq))\n",
    "print('Torque cutting wheel [MNm]: {}'.format(f_sup_torq))\n",
    "print('Advance speed [mm/min]: {}'.format(f_inf_adv))\n",
    "print('Advance speed [mm/min]: {}'.format(f_sup_adv))\n",
    "\n",
    "print('Torque cutting wheel [MNm] min: {}'.format(f_min_torq))\n",
    "print('Advance speed [mm/min] min: {}'.format(f_min_adv))\n",
    "\n",
    "print('Torque cutting wheel [MNm] min25: {}'.format(f_min_torq25))\n",
    "print('Advance speed [mm/min] min25: {}'.format(f_min_adv25))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg=dfxls[(dfxls['Torque cutting wheel [MNm]']>f_min_torq25) &\n",
    "          (dfxls['Advance speed [mm/min]']>f_min_adv25)].filter(regex='(Pressure excavation chamber|Fill level)')\n",
    "col_ls = dfg.columns.tolist()\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Pressure excavation chamber \",\"Pr_Ex_Ch_\"),col_ls))\n",
    "col_ls = list(map(lambda x: str.replace(x,\"Fill level working chamber\",\"Fill_Lev_WCh\"),col_ls))\n",
    "dfg.columns = col_ls\n",
    "\n",
    "print('dfg shape {}'.format(dfg.shape))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotto il grafico multiplo di correlazione\n",
    "\n",
    "corrgraph(dfg.loc[:, dfg.columns != 'classi'], 'corr_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['classi']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "# dfg1 = dfxls[dfxls['S-1048_ADVANCE_ADVANCE_NO [-]']==4203]\n",
    "\n",
    "dfg1 = dfxls.copy()\n",
    "\n",
    "Y0 = dfg1.filter(regex='P0.1.*[m³/h]',axis=1)/dfg1.filter(regex='P0.1.*[m³/h]',axis=1).max()\n",
    "X0 = dfg1['datestamp']\n",
    "\n",
    "Y6 = dfg1.filter(regex='P0.2.*[m³/h]',axis=1)/dfg1.filter(regex='P0.2.*[m³/h]',axis=1).max()\n",
    "X6 = dfg1['datestamp']\n",
    "\n",
    "\n",
    "Y = dfg1[dfg1.classi==0].filter(regex='Fill.*level',axis=1)\n",
    "X = dfg1[dfg1.classi==0]['datestamp']\n",
    "\n",
    "Y1 = dfg1[dfg1.classi==1].filter(regex='Fill.*level',axis=1)\n",
    "X1 = dfg1[dfg1.classi==1]['datestamp']\n",
    "\n",
    "Y2 = dfg1[dfg1.classi==2].filter(regex='Fill.*level',axis=1)\n",
    "X2 = dfg1[dfg1.classi==2]['datestamp']\n",
    "\n",
    "Y3 = dfg1[dfg1.state=='fulloper'].filter(regex='Fill.*level',axis=1)\n",
    "X3 = dfg1[dfg1.state=='fulloper']['datestamp']\n",
    "\n",
    "Y4 = dfg1[dfg1.state=='stall_rotating'].filter(regex='Fill.*level',axis=1)\n",
    "X4 = dfg1[dfg1.state=='stall_rotating']['datestamp']\n",
    "\n",
    "Y5 = dfg1[dfg1.state=='stall_stand'].filter(regex='Fill.*level',axis=1)\n",
    "X5 = dfg1[dfg1.state=='stall_stand']['datestamp']\n",
    "\n",
    "## PLOT\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax.plot(X0,Y0,c='grey',label='P.01')\n",
    "ax.plot(X6,Y6,c='lightblue',label='P0.2')\n",
    "\n",
    "# ax.scatter(X,Y, label='Gauss0',s=20)\n",
    "# ax.scatter(X1,Y1, label='Gauss1')\n",
    "# ax.scatter(X2,Y2, label='Gauss2')\n",
    "ax.scatter(X3,Y3,c='g',label='fulloper')\n",
    "ax.scatter(X4,Y4,c='y',label='stall_rotating')\n",
    "ax.scatter(X5,Y5,c='r',label='stall_stand')\n",
    "\n",
    "plt.xlim('2020-01-07 07:00:00','2020-01-08 07:00:00')\n",
    "plt.ylim(0,1.2)\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left', frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg1.datestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfxls[dfxls.classi==0].filter(regex='Press.*4',axis=1)\n",
    "Y = dfxls[dfxls.classi==0]['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls['S-1048_ADVANCE_ADVANCE_NO [-]'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "dfg1 = dfxls[dfxls['S-1048_ADVANCE_ADVANCE_NO [-]']==4202]\n",
    "\n",
    "Y = dfg1[dfg1.classi==0].filter(regex='Fill.*level',axis=1)\n",
    "X = dfg1[dfg1.classi==0]['Advance speed [mm/min]']\n",
    "\n",
    "Y1 = dfg1[dfg1.classi==1].filter(regex='Fill.*level',axis=1)\n",
    "X1 = dfg1[dfg1.classi==1]['Advance speed [mm/min]']\n",
    "\n",
    "Y2 = dfg1[dfg1.classi==2].filter(regex='Fill.*level',axis=1)\n",
    "X2 = dfg1[dfg1.classi==2]['Advance speed [mm/min]']\n",
    "\n",
    "Y3 = dfg1[dfg1.state=='fulloper'].filter(regex='Fill.*level',axis=1)\n",
    "X3 = dfg1[dfg1.state=='fulloper']['Advance speed [mm/min]']\n",
    "\n",
    "Y4 = dfg1[dfg1.state=='stall_rotating'].filter(regex='Fill.*level',axis=1)\n",
    "X4 = dfg1[dfg1.state=='stall_rotating']['Advance speed [mm/min]']\n",
    "\n",
    "Y5 = dfg1[dfg1.state=='stall_stand'].filter(regex='Fill.*level',axis=1)\n",
    "X5 = dfg1[dfg1.state=='stall_stand']['Advance speed [mm/min]']\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "# ax.scatter(X,Y, label='Gauss0',s=20)\n",
    "# ax.scatter(X1,Y1, label='Gauss1')\n",
    "# ax.scatter(X2,Y2, label='Gauss2')\n",
    "ax.scatter(X3,Y3,c='g',label='fulloper')\n",
    "ax.scatter(X4,Y4,c='y',label='stall_rotating')\n",
    "ax.scatter(X5,Y5,c='r',label='stall_stand')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left', frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxls.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg1.filter(regex=\"date\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
